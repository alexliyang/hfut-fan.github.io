<!DOCTYPE html>




<html class="theme-next pisces" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Deep Convolutional NetWork,Semantic Segmentation,DeepLab," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="DeepLab系列是针对Semantic Segmentation任务提出的一系列模型，主要使用了DCNN、CRF、空洞卷积做密集预测。重点讨论了空洞卷积的使用，并提出的获取多尺度信息的ASPP模块，在多个数据集上获得了state-of-the-art 表现.">
<meta name="keywords" content="Deep Convolutional NetWork,Semantic Segmentation,DeepLab">
<meta property="og:type" content="article">
<meta property="og:title" content="语义分割论文-DeepLab系列">
<meta property="og:url" content="http://hfut-fan.github.io/2018/01/22/语义分割论文-DeepLab系列/index.html">
<meta property="og:site_name" content="DelphiFan&#39;s Blog">
<meta property="og:description" content="DeepLab系列是针对Semantic Segmentation任务提出的一系列模型，主要使用了DCNN、CRF、空洞卷积做密集预测。重点讨论了空洞卷积的使用，并提出的获取多尺度信息的ASPP模块，在多个数据集上获得了state-of-the-art 表现.">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180122/AK2hhck8LJ.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180122/JKc0CmjakE.gif">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180122/22ECkI3dFI.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180122/1cihECHda6.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180122/2J7I42mheI.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180122/5bJf9hJIdh.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180122/4j8FGciJ87.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180122/0AKjEc8Jlg.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180122/jAfA6BKm25.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180122/hcDK7ef2e6.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/F74AGfFdfb.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/bGK3DJ8d37.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/ECK88k4l3H.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/50HmA4g5h2.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/8giA72Ch1H.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/773C1J0gL6.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/CFmKmmf5Lf.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/f5BFeE0cb7.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/AG7KmDcB8D.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/Gbm43FclDe.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/dKl1fcabK2.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/9c7dFHGHKa.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/haKHEfl5JE.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/F1a70LImD4.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/LCBGdE3AGl.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/ae12EH6gG0.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/5CC8f3hhdB.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/im967HG9IA.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/GDl79aALEC.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/je0if5IHmi.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/eb5hhdeKfF.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/C8kDdJGHA0.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/IL1AGa6BdB.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/5D80iJ71J2.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/JlHL1c5Gek.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/EDflDAH02J.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/G0acji3Cmd.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/c6l0L60AKf.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/hhJ1L9g27m.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/J9I9mBlF0C.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/hADC1i17Hk.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/m327dE1c8m.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/4lbc7h08f9.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/kII63g7c9D.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/08GkcLGKFE.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/B8j8m02K1h.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/iad2fCbded.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/6ha93fJd5G.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/fDfFha2J6f.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/Jc54jAJEK0.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/80b79b199B.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180123/7jC81BBe4m.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/g1mJ1d2GBc.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/9iAG3JkF4B.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/984fKB8f8G.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/c2KLkkL4lE.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/bJ9l0ABbj3.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/kG35IL1J3F.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/68GkJDiC2F.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/7879h4g497.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/hkHGlL4gL3.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/AClklDIKdD.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/EliFfHIjdC.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/KLB8ebIIm3.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/96E8cmakDl.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/GEdkAbblb8.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/Ej5HmI5iAI.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/KJbbHfe0D2.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/0dCc9lH84l.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/HDl01aKf1h.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/e1KCgi7l4b.png">
<meta property="og:image" content="http://owv7la1di.bkt.clouddn.com/blog/180124/ebKKci98E8.png">
<meta property="og:updated_time" content="2018-01-29T02:45:00.983Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="语义分割论文-DeepLab系列">
<meta name="twitter:description" content="DeepLab系列是针对Semantic Segmentation任务提出的一系列模型，主要使用了DCNN、CRF、空洞卷积做密集预测。重点讨论了空洞卷积的使用，并提出的获取多尺度信息的ASPP模块，在多个数据集上获得了state-of-the-art 表现.">
<meta name="twitter:image" content="http://owv7la1di.bkt.clouddn.com/blog/180122/AK2hhck8LJ.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: false,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://hfut-fan.github.io/2018/01/22/语义分割论文-DeepLab系列/"/>





  <title>语义分割论文-DeepLab系列 | DelphiFan's Blog</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">DelphiFan's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Man proposes , God disposes.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hfut-fan.github.io/2018/01/22/语义分割论文-DeepLab系列/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="DFan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="DelphiFan's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">语义分割论文-DeepLab系列</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-22T19:47:42+08:00">
                2018-01-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-Reading/" itemprop="url" rel="index">
                    <span itemprop="name">Paper Reading</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 浏览
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>次
            </span>
          

          

          
              <div class="post-description">
                  DeepLab系列是针对Semantic Segmentation任务提出的一系列模型，主要使用了DCNN、CRF、空洞卷积做密集预测。重点讨论了空洞卷积的使用，并提出的获取多尺度信息的ASPP模块，在多个数据集上获得了state-of-the-art 表现.
              </div>
          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <a id="more"></a>
<h1 id="DeepLabv1"><a href="#DeepLabv1" class="headerlink" title="DeepLabv1"></a>DeepLabv1</h1><p>Semantic image segmentation with deep convolutional nets and fully connected CRFs</p>
<p>原文地址：<a href="https://arxiv.org/pdf/1412.7062v3.pdf" target="_blank" rel="external">DeepLabv1</a></p>
<p>收录：ICLR 2015 (International Conference on Learning Representations)</p>
<p>代码:</p>
<ul>
<li><a href="https://bitbucket.org/deeplab/deeplab-public/overview" target="_blank" rel="external">bitbucket-Caffe</a></li>
<li><a href="https://github.com/TheLegendAli/DeepLab-Context" target="_blank" rel="external">github-Caffe</a></li>
</ul>
<hr>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>DeepLab是结合了深度卷积神经网络(DCNNs)和概率图模型(DenseCRFs)的方法。在实验中发现DCNNs做语义分割时精准度不够的问题，根本原因是DCNNs的高级特征的平移不变性(即高层次特征映射)。DeepLab解决这一问题的方法是通过将DCNNs层的响应和完全连接的条件随机场(CRF)结合。同时模型创新性的将<code>hole</code>(即空洞卷积)算法应用到DCNNs模型上，在现代GPU上运行速度达到了8FPS。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>相比于传统的视觉算法(SIFT或HOG)，DCNN以其end-to-end方式获得了很好的效果。这样的成功部分可以归功于DCNN对图像转换的平移不变性(invariance)，这根本是源于重复的池化和下采样组合层。平移不变性增强了对数据分层抽象的能力，但同时可能会阻碍低级(low-level)视觉任务,例如姿态估计、语义分割等，在这些任务中我们倾向于精确的定位而不是抽象的空间关系。</p>
<p>DCNN在图像标记任务中存在两个技术障碍：</p>
<ul>
<li>信号下采样</li>
<li>空间不敏感(invariance)</li>
</ul>
<p>第一个问题涉及到：在DCNN中重复最大池化和下采样带来的分辨率下降问题，分辨率的下降会丢失细节。DeepLab是采用的<code>atrous</code>(带孔)算法扩展感受野，获取更多的上下文信息。</p>
<p>第二个问题涉及到：分类器获取以对象中心的决策是需要空间变换的不变性，这天然的限制了DCNN的定位精度，DeepLab采用完全连接的条件随机场(DenseCRF)提高模型捕获细节的能力。</p>
<p>论文的主要贡献在于：</p>
<ul>
<li>速度：带<code>atrous</code>算法的DCNN可以保持8FPS的速度，全连接CRF平均推断需要0.5s</li>
<li>准确：在PASCAL语义分割挑战中获得了第二的成绩</li>
<li>简单：DeepLab是由两个非常成熟的模块(DCNN和CRFs)级联而成</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>DeepLab系统应用在语义分割任务上，目的是做逐像素分类的，这与使用两阶段的DCNN方法形成鲜明对比(指<a href="http://blog.csdn.net/u011974639/article/details/78053203" target="_blank" rel="external">R-CNN</a>等系列的目标检测工作)，R-CNN系列的做法是原先图片上获取候选区域，再送到DCNN中获取分割建议，重新排列取结果。虽然这种方法明确地尝试处理前段分割算法的本质，但在仍没有明确的利用DCNN的预测图。</p>
<p>我们的系统与其他先进模型的主要区别在于DenseCRFs和DCNN的结合。是将每个像素视为CRF节点，利用远程依赖关系，并使用CRF推理直接优化DCNN的损失函数。Koltun(2011)的工作表明完全连接的CRF在语义分割下非常有效。</p>
<p>也有其他组采取非常相似的方向，将DCNN和密集的CRF结合起来，我们已经更新提出了DeepLab系统(指的是DeepLabV2)。</p>
<hr>
<h2 id="密集分类下的卷积神经网络"><a href="#密集分类下的卷积神经网络" class="headerlink" title="密集分类下的卷积神经网络"></a>密集分类下的卷积神经网络</h2><p>这里先描述一下DCNN如何设计，我们调整VGG16模型，转为一个可以有效提取特征的语义分割系统。具体来说，先将VGG16的FC层转为卷积层，模型变为全卷积的方式，在图像的原始分辨率上产生非常稀疏的计算检测分数(步幅32,$步幅=\frac{输入尺寸}{输出特征尺寸}$)，为了以更密集(步幅8)的计算得分,我们在最后的两个最大池化层不下采样(padding到原大小)，再通过2或4的采样率的空洞卷积对特征图做采样扩大感受野，缩小步幅。</p>
<h3 id="空洞卷积的使用"><a href="#空洞卷积的使用" class="headerlink" title="空洞卷积的使用"></a>空洞卷积的使用</h3><p>简单介绍下空洞卷积在卷积神经网络的使用(这在DeepLabv3中有更详细的讨论)。</p>
<p>在1-D的情况下，我们扩大输入核元素之间的步长，如下图Input stride：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180122/AK2hhck8LJ.png" alt="mark"></p>
<p>如果不是很直观，看下面的在二维图像上应用空洞卷积：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180122/JKc0CmjakE.gif" alt="mark"></p>
<p>蓝色部分是输入：$7×7$的图像<br>青色部分是输出：$3×3$的图像<br>空洞卷积核：$3x3$ 采样率(扩展率)为2  无padding</p>
<p>这种带孔的采样又称atrous算法，可以稀疏的采样底层特征映射，该方法具有通常性，并且可以使用任何采样率计算密集的特征映射。在VGG16中使用不同采样率的空洞卷积，可以让模型再密集的计算时，明确控制网络的感受野。保证DCNN的预测图可靠的预测图像中物体的位置。</p>
<p>训练时将预训练的VGG16的权重做fine-tune，损失函数取是<strong>输出的特征图与ground truth下采样8倍</strong>做交叉熵和；测试时取<strong>输出图双线性上采样8倍</strong>得到结果。但DCNN的预测物体的位置是粗略的，没有确切的轮廓。在卷积网络中，因为有多个最大池化层和下采样的重复组合层使得模型的具有平移不变性，我们在其输出的high-level的基础上做定位是比较难的。这需要做分类精度和定位精度之间是有一个自然的折中。</p>
<p>解决这个问题的工作，主要分为两个方向：</p>
<ul>
<li>第一种是<strong>利用卷积网络中多个层次的信息</strong></li>
<li>第二种是<strong>采样超像素表示，实质上是将定位任务交给低级的分割方法</strong></li>
</ul>
<p>DeepLab是结合了DCNNs的识别能力和全连接的CRF的细粒度定位精度，寻求一个结合的方法，结果证明能够产生准确的语义分割结果。</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180122/22ECkI3dFI.png" alt="mark"></p>
<h3 id="CRF在语义分割上的应用"><a href="#CRF在语义分割上的应用" class="headerlink" title="CRF在语义分割上的应用"></a>CRF在语义分割上的应用</h3><p>传统上，CRF已被用于平滑噪声分割图。通常，这些模型包含耦合相邻节点的能量项，有利于相同标签分配空间近端像素。定性的说，这些短程的CRF主要功能是<strong>清除在手工特征基础上建立的弱分类器的虚假预测</strong>。</p>
<p>与这些弱分类器相比，现代的DCNN体系产生质量不同的预测图，通常是比较平滑且均匀的分类结果(即以前是弱分类器预测的结果，不是很靠谱，现在DCNN的预测结果靠谱多了)。在这种情况下，使用短程的CRF可能是不利的，因为我们的目标是恢复详细的局部结构，而不是进一步平滑。而有工作证明可用全连接的CRF来提升分割精度。</p>
<div class="note success"><p><strong>CRF在语义分割上的应用：</strong></p>
<p>对于每个像素位置$i$具有隐变量$x_i$(这里隐变量就是像素的真实类别标签，如果预测结果有21类，则$(i∈{1,2,..,21})$)，还有对应的观测值$y_i$(即像素点对应的颜色值)。以像素为节点，像素与像素间的关系作为边，构成了一个条件随机场(CRF)。通过观测变量$y_i$来推测像素位置$i$对应的类别标签$x_i$。条件随机场示意图如下<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180122/1cihECHda6.png" alt="mark"></p>
<p>条件随机场符合吉布斯分布($x$是上面的观测值，下面省略全局观测$I$)：$$P(x|I)=\frac{1}{Z}\exp(-E(x|I))$$</p>
<p>全连接的CRF模型使用的能量函数$E(x)$为:$$E(x)=\sum_{i}\theta_i(x_i)+\sum_{ij}\theta_{ij}(x_i,x_j)$$这分为一元势函数$\theta_i(x_i)$和二元势函数$\theta_{ij}(x_i,x_j)$两部分.</p>
<ul>
<li>一元势函数是定义在观测序列位置$i$的状态特征函数，用于<strong>刻画观测序列对标记变量的影响</strong>。在这里定义为: $$\theta_i(x_i)=-\log P(x_i)$$说白了，就是我们观测到像素点$i$的当前像素为$y_i$，则其对应为标签$x_i$的概率值(例如在城市道路任务中，观测到像素点为黑色，对应车子的可能比天空可能要大)。以前这个一元势函数是通过一些分类器完成的，现在DeepLab中有了DCNN来做像素分割，<strong>故这里$P(x_i)$是取DCNN计算关于像素$i$的输出的标签分配概率。</strong></li>
</ul>
<ul>
<li><p>二元势函数是定义在不同观测位置上的转移特征函数，用于<strong>刻画变量之间的相关关系以及观测序列对其影响</strong>。在这里定义为:$$\theta_{ij}(x_i,x_j)=\mu(x_i,x_j)\sum_{m=1}^K\omega_m  k^m(f_i,f_j)$$</p>
<ul>
<li>其中$  if \ x_i ≠ x_j \ 则\mu(x_i,x_j)=1  ；否则 \mu(x_i,x_j)=0 $。因为是全连接，所有每个像素对都会有值.<ul>
<li>$k^m(f_i,f_j)$是$(f_i,f_j)$之间的高斯核，$f_i$是像素$i$的特征向量，例如像素点$i$的特征向量$f_i$用$(x,y,r,g,b)$表示。对应的权重为$\omega_m$</li>
<li>在DeepLab中高斯核采用双边位置和颜色组合，式为$$\omega_1\exp-\frac{||p_i-p_j||^2}{2\sigma_{\alpha}^2}-\frac{||I_i-I_j||^2}{2\sigma_{\beta}^2})+\omega_2\exp(-\frac{||p_i-p_j||^2}{2\sigma_{\gamma}^2})$$ 第一核取决于像素位置($p$)和像素颜色强度($I$)，第二个核取决于像素位置($p$).</li>
</ul>
</li>
</ul>
<p>说白了<strong>，二元势函数是描述像素和像素之间的关系，</strong>如果比较相似，那可能是一类，否则就裂开，这可以细化边缘。一般的二元势函数只取像素点与周围像素之间的边，这里使用的是全连接，即像素点与其他所有像素之间的关系。</p>
</li>
</ul>
<p>这个公式看起来是很麻烦的，实际上计算时分解近似的平均场然后再计算，感兴趣可参考对应论文.</p></div>
<h3 id="多尺度预测"><a href="#多尺度预测" class="headerlink" title="多尺度预测"></a>多尺度预测</h3><p>论文还探讨了使用多尺度预测提高边界定位效果。具体的，在输入图像和前四个最大池化层的输出上附加了两层的MLP(第一层是128个$3×3$卷积，第二层是128个$1×1$卷积)，最终输出的特征映射送到模型的最后一层辅助预测，合起来模型最后的softmax层输入特征多了$5×128=640$个通道，实验表示多尺度有助于提升预测结果，但是效果不如CRF明显。</p>
<hr>
<h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><p>测试细节：</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>设置</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据集</td>
<td>PASCAL VOC 2012 segmentation benchmark</td>
</tr>
<tr>
<td>DCNN模型</td>
<td>权重采用预训练的VGG16</td>
</tr>
<tr>
<td>DCNN损失函数</td>
<td>交叉熵</td>
</tr>
<tr>
<td>训练器</td>
<td>SGD，batch=20</td>
</tr>
<tr>
<td>学习率</td>
<td>初始为0.001，最后的分类层是0.01。每2000次迭代乘0.1</td>
</tr>
<tr>
<td>权重</td>
<td>0.9的动量， 0.0005的衰减</td>
</tr>
</tbody>
</table>
<p>DeepLab由DCNN和CRF组成，训练策略是分段训练，即DCNN的输出是CRF的一元势函数，在训练CRF时是固定的。在对DCNN做了fine-tune后，对CRF做交叉验证。这里使用$\omega_2=3$和$\sigma_{\gamma}=3$在小的交叉验证集上寻找最佳的$\omega_1,\sigma_{\alpha},\sigma_{\beta}$,采用从粗到细的寻找策略。</p>
<h3 id="CRF和多尺度的表现"><a href="#CRF和多尺度的表现" class="headerlink" title="CRF和多尺度的表现"></a>CRF和多尺度的表现</h3><p>在验证集上的表现：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180122/2J7I42mheI.png" alt="mark"></p>
<p>可以看到带CRF和多尺度的(<code>MSc</code>)的DeepLab模型效果明显上升了。</p>
<p>多尺度的视觉表现：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180122/5bJf9hJIdh.png" alt="mark"></p>
<p>第一行是普通输出，第二行是带多尺度的输出，可以看出多尺度输出细节部分要好点</p>
<h3 id="离散卷积的表现"><a href="#离散卷积的表现" class="headerlink" title="离散卷积的表现"></a>离散卷积的表现</h3><p>在使用离散卷积的过程中，可控制离散卷积的采样率来扩展特征感受野的范围，不同配置的参数如下：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180122/4j8FGciJ87.png" alt="mark"></p>
<p>同样的实验结果：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180122/0AKjEc8Jlg.png" alt="mark"></p>
<p>带FOV的即不同离散卷积的配置.可以看到大的离散卷积效果会好一点.</p>
<h3 id="与其他模型相比"><a href="#与其他模型相比" class="headerlink" title="与其他模型相比"></a>与其他模型相比</h3><p><img src="http://owv7la1di.bkt.clouddn.com/blog/180122/jAfA6BKm25.png" alt="mark"></p>
<p>与其他先进模型相比，DeepLab捕获到了更细节的边界.</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>DeepLab创造性的结合了DCNN和CRF产生一种新的语义分割模型，模型有准确的预测结果同时计算效率高。在PASCAL VOC 2012上展现了先进的水平。DeepLab是卷积神经网络和概率图模型的交集，后续可考虑将CNN和CRF结合到一起做end-to-end训练。</p>
<p>后续的DeepLabv2~3是DeepLabv1的升级版，进一步讨论空洞卷积和CRF的使用~</p>
<hr>
<hr>
<hr>
<h1 id="DeepLabv2"><a href="#DeepLabv2" class="headerlink" title="DeepLabv2"></a>DeepLabv2</h1><p>DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</p>
<p>原文地址：<a href="https://arxiv.org/abs/1606.00915" target="_blank" rel="external">DeepLabv2</a></p>
<p>收录：TPAMI2017 (IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017)<br>代码:</p>
<ul>
<li><a href="https://github.com/DrSleep/tensorflow-deeplab-resnet" target="_blank" rel="external">TensorFlow</a></li>
<li><a href="https://bitbucket.org/aquariusjay/deeplab-public-ver2" target="_blank" rel="external">bitbucket-Caffe</a></li>
</ul>
<p>DeepLabv2可以看成是DeepLabv1的强化版，在空洞卷积和全连接的CRF使用上与DeepLabv1类似~ </p>
<hr>
<h2 id="Abstract-1"><a href="#Abstract-1" class="headerlink" title="Abstract"></a>Abstract</h2><p>本文为使用深度学习的语义分割任务，做出了三个主要贡献：</p>
<ul>
<li><p>首先，<strong>强调使用空洞卷积，作为密集预测任务的强大工具</strong>。空洞卷积能够明确地控制DCNN内计算特征响应的分辨率，即可以有效的扩大感受野，在不增加参数量和计算量的同时获取更多的上下文。</p>
</li>
<li><p>其次，<strong>我们提出了空洞空间卷积池化金字塔(atrous spatial pyramid pooling (ASPP))，以多尺度的信息得到更强健的分割结果</strong>。ASPP并行的采用多个采样率的空洞卷积层来探测，以多个比例捕捉对象以及图像上下文。</p>
</li>
<li><p>最后，<strong>通过组合DCNN和概率图模型，改进分割边界结果</strong>。在DCNN中最大池化和下采样组合实现可平移不变性，但这对精度是有影响的。通过将最终的DCNN层响应与全连接的CRF结合来克服这个问题。</p>
</li>
</ul>
<p>论文提出的DeepLabv2在PASCAL VOC2012上表现优异，并在PASCAL-Context, PASCAL-Person-Part, and Cityscapes上都表现不错。</p>
<h2 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h2><p>DCNN(Deep Convolutional Neural Networks)将CV系统的性能推向了一个新的高度。成功的关键在于DCNN对于局部图像转换的内在不变性。这使得模型可以学习高层次的抽象表示。这种不变性带了高层次抽象表示的同时也可能妨碍诸如语义分割之类的密集预测任务，在空间信息上是不理想的。</p>
<p>将DCNN应用在语义分割任务上，我们着重以下三个问题：</p>
<ul>
<li>降低特征分辨率</li>
<li>多个尺度上存在对象</li>
<li>由于DCNN的内在不变性，定位精度底</li>
</ul>
<p>接下来我们讨论这些问题，并着重解决这些问题。</p>
<p>第一个挑战是因为：DCNN连续的最大池化和下采样组合引起的空间分辨率下降，为了解决这个问题，<strong>DeepLabv2在最后几个最大池化层中去除下采样，取而代之的是使用空洞卷积，以更高的采样密度计算特征映射</strong>。</p>
<p>第二个挑战是因为：在多尺度上存在物体。解决这一问题有一个标准方法是将一张图片缩放不同版本，汇总特征或最终预测得到结果，实验表明能提高系统的性能，但这个增加了计算特征响应，需要大量的存储空间。<strong>我们受到<a href="http://blog.csdn.net/u011974639/article/details/78053203#sppnet" target="_blank" rel="external">spatial pyramid pooling(SPP)</a>的启发，提出了一个类似的结构，在给定的输入上以不同采样率的空洞卷积并行采样，相当于以多个比例捕捉图像的上下文，称为ASPP(atrous spatial pyramid pooling)模块</strong>。</p>
<p>第三个挑战涉及到以下情况：对象分类要求空间变换不变性，而这影响了DCNN的空间定位精度。解决这一问题的一个做法是在计算最终分类结果时，使用跳跃层，将前面的特征融合到一起<strong>。DeepLabv2是采样全连接的CRF在增强模型捕捉细节的能力。</strong></p>
<p>下面是一个DeepLab的例子：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180122/hcDK7ef2e6.png" alt="mark"></p>
<p>总体步骤如下：</p>
<ul>
<li>输入经过改进的DCNN(带空洞卷积和ASPP模块)得到粗略预测结果，即<code>Aeroplane Coarse Score map</code></li>
<li>通过双线性插值扩大到原本大小，即<code>Bi-linear Interpolation</code></li>
<li>再通过全连接的CRF细化预测结果，得到最终输出<code>Final Output</code></li>
</ul>
<p>总结一下，DeepLabv2的主要优点在于：</p>
<ul>
<li>速度： DCNN在现代GPU上以8FPS运行，全连接的CRF在CPU上需要0.5s</li>
<li>准确性：在PASCAL VOC2012,PASCAL-Context, PASCALPerson-Part,Cityscapes都获得的优异的结果</li>
<li>简单性：系统是由两个非常成熟的模块级联而成，DCNNs和CRFs</li>
</ul>
<p>本文DeepLabv2是在DeepLabv1的基础上做了改进，基础层由VGG16换成了更先进的ResNet，添加了多尺度和ASPP模块技术得到了更好的分割结果。</p>
<h2 id="Related-Work-1"><a href="#Related-Work-1" class="headerlink" title="Related Work"></a>Related Work</h2><p>DCNN应用于语义分割任务上，涉及到分类和定位细化，工作的核心是把两个任务结合起来。</p>
<p>基于DCNN的语义分割系统有三种大类：</p>
<ul>
<li><p>第一种：采样基于DCNN的自下而上的图像分割级联。将形状信息合并的分类过程中，这些方法得益于传递的形状边界信息，从而能够很好分割。但这不能从错误中恢复出来。(开始错就会一直错)</p>
</li>
<li><p>第二种：依靠DCNN做密集计算得到预测结果，并将多个独立结果做耦合。其中一种是在多个分辨率下使用DCNN，使用分割树来平滑预测结果。最近有使用skip layer来级联内部的计算特征用于分类。</p>
</li>
<li><p>第三种：使用DCNN直接做密集的像素级别分类。直接使用全卷积方式应用在整个图像，将DCNN后续的FC层转为卷积层，为了处理空间定位问题，使用上采样和连接中间层的特征来细化结果。</p>
</li>
</ul>
<p>我们的工作是建立在这些工作的基础上，自从第一个版本DeepLabv1公布，许多工作采用了其中一个或两个关键要素：在DCNN的结果上使用全连接的CRF细化结果；使用空洞卷积做密集的特征提取。也有许多工作着重这两者间end-to-end的探索，将DCNN和CRF一起做联合学习。</p>
<p><strong>空洞卷积能在保持计算量和参数量的同时扩大感受野，配合使用金字塔池化方案可以聚合多尺度的上下文信息，可通过空洞卷积控制特征分辨率、配合更先进的DCNN模型、多尺度联合技术、并在DCNN之上集成全连接的CRF可以获取更好的分割结果。</strong></p>
<p>DCNN和CRF的组合不是新话题，以前的作品着重于应用局部CRF，这忽略像素间的长期依赖。而DeepLab采用的是全连接的CRF模型，其中高斯核可以捕获长期依赖性，从而得到较好的分割结果。</p>
<hr>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="空洞卷积用于密集特征提取和扩大感受野"><a href="#空洞卷积用于密集特征提取和扩大感受野" class="headerlink" title="空洞卷积用于密集特征提取和扩大感受野"></a>空洞卷积用于密集特征提取和扩大感受野</h3><p>DCNN中连续的最大池化和下采样重复组合层大大的降低了最终的feature map的空间分辨率，有一些补救方式是使用deconvolutional layer(转置卷积，用于扩大特征映射分辨率)，但这需要额外的空间和计算量。 我们主张使用空洞卷积，可以以任何特征响应分辨率计算任何层的特征映射。</p>
<p>关于空洞卷积使用详解：</p>
<p>首先考虑一维信号，空洞卷积输出为$y[i]$,输入为$x[i]$,长度K的滤波器为$\omega[k]$。定义为:$$y[k]=\sum_{k=1}^Kx[i+r·k] \omega[k] $$ 输入采样的步幅为参数$r$，标准的采样率是$r=1$.如下图(a)所示:</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/F74AGfFdfb.png" alt="mark"></p>
<p>图(b)是采样率$r=2$的采样情况.</p>
<p>在看看在二维信号(图片)上使用空洞卷积的表现,给定一个图像：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/bGK3DJ8d37.png" alt="mark"></p>
<ul>
<li>上分支：首先下采样将分辨率降低2倍，做卷积。再上采样得到结果。本质上这只是在原图片的1/4内容上做卷积响应。</li>
<li>下分支：如果我们将全分辨率图像做空洞卷积(采样率为2，核大小与上面卷积核相同)，直接得到结果。这样可以计算出整张图像的响应，如上图所示，这样做效果更佳。</li>
</ul>
<p>空洞卷积能够放大滤波器的感受野，速率$r$引入$r-1$个零，有效的将感受野从$k×k$扩展到$k_e=k+(k-1)(r-1)$，而不增加参数和计算量。在DCNN中，常见的做法是混合使用空洞卷积以高的分辨率(理解为采样密度)计算最终的DCNN网络响应。DeepLabv2中使用空洞卷积将特征的密度提升4倍，将输出的特征响应双线性插值上采样8倍恢复到原始的分辨率。</p>
<h3 id="使用ASPP模块表示多尺度图像"><a href="#使用ASPP模块表示多尺度图像" class="headerlink" title="使用ASPP模块表示多尺度图像"></a>使用ASPP模块表示多尺度图像</h3><p>许多工作证明使用图像的多尺度信息可以提高DCNN分割不同大小物体的精度，我们尝试了两种方法来处理语义分割中尺度变化。</p>
<ul>
<li><p>第一种方法是标准的多尺度处理：将放缩输入为不同版本，分别输入到DCNN中，融合得到分数图得到预测结果。这可以显著的提升预测结果，但是这也耗费了大量的计算力和空间。</p>
</li>
<li><p>第二种方法是受到 <a href="http://blog.csdn.net/u011974639/article/details/78053203#sppnet" target="_blank" rel="external">SPPNet中SPP模块</a>结构的启发。<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/ECK88k4l3H.png" alt="mark"><br>上图为SPPNet中SPP模块样式。<br>DeepLabv2的做法与SPPNet类似，并行的采用多个采样率的空洞卷积提取特征，再将特征融合，类似于空间金字塔结构，形象的称为Atrous Spatial Pyramid Pooling (ASPP)。示意图如下：</p>
</li>
</ul>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/50HmA4g5h2.png" alt="mark"></p>
<p>在同一<code>Input Feature Map</code>的基础上，并行的使用4个空洞卷积，空洞卷积配置为$r={6,12,18,24}$，核大小为$3×3$。最终将不同卷积层得到的结果做像素加融合到一起.</p>
<h3 id="使用全连接CRF做结构预测用于恢复边界精度"><a href="#使用全连接CRF做结构预测用于恢复边界精度" class="headerlink" title="使用全连接CRF做结构预测用于恢复边界精度"></a>使用全连接CRF做结构预测用于恢复边界精度</h3><p>因为最大池化和下采样组合，DCNN的高层特征具有内在不变性(这一点反复说了很多遍了~)。分类性能和定位准确性之间的折中似乎是固有的。如下图，DCNN可以预测对象存在和粗略的位置，但不能精确的划定其边界：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/8giA72Ch1H.png" alt="mark"></p>
<p>我们将DCNN和全连接的CRF组合到一起，这在前面的<a href="http://blog.csdn.net/u011974639/article/details/79134409#t6" target="_blank" rel="external">DeepLabv1-CRF在语义分割上的应用</a>中详解过了，这部分就跳过了~</p>
<hr>
<h2 id="Experiment-1"><a href="#Experiment-1" class="headerlink" title="Experiment"></a>Experiment</h2><p>DeepLabv2在PASCAL VOC 2012, PASCAL-Context, PASCALPerson- Part, and Cityscapes四个数据集上做了评估。</p>
<p>测试细节：</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>设置</th>
</tr>
</thead>
<tbody>
<tr>
<td>DCNN模型</td>
<td>权重采用预训练的VGG16，ResNet101</td>
</tr>
<tr>
<td>DCNN损失函数</td>
<td>输出的结果与ground truth下采样8倍做像素交叉熵</td>
</tr>
<tr>
<td>训练器</td>
<td>SGD，batch=20</td>
</tr>
<tr>
<td>学习率</td>
<td>初始为0.001，最后的分类层是0.01。每2000次迭代乘0.1</td>
</tr>
<tr>
<td>权重</td>
<td>0.9的动量， 0.0005的衰减</td>
</tr>
</tbody>
</table>
<p>模型对预训练的VGG16和ResNet101模型做fine-tune。训练时DCNN和CRF的是解耦的，即分别训练，训练CRF时DCNN输出作为CRF的一元势函数输入是固定的。</p>
<p>大概训练验证手段是对CRF做交叉验证。使用$\omega_2=3$和$\sigma_{\gamma}=3$在小的交叉验证集上寻找最佳的$\omega_1,\sigma_{\alpha},\sigma_{\beta}$,采用从粗到细的寻找策略。</p>
<p>不同卷积核大小和采样率的组合下的模型：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/773C1J0gL6.png" alt="mark"></p>
<p>DeepLab-LargeFOV(kernel size3×3, r = 12)取得了一个很好的平衡。可以看出小卷积核配合高采样率可以保持感受野的前提下显著减少参数量，同时加快计算速度，而且分割效果也很好。使用CRF做后端处理可以保持平均提升了3~5%的性能。</p>
<h3 id="PASCAL-VOC-2012"><a href="#PASCAL-VOC-2012" class="headerlink" title="PASCAL VOC 2012"></a>PASCAL VOC 2012</h3><p>在PASCAL VOC 2012上评估了DeepLab-CRF-LargeFOV模型，这里做了三个主要的改进：</p>
<ul>
<li>1.训练期间使用不同的学习策略；</li>
<li>2.使用ASPP模块；</li>
<li>3.使用深度网络和多层次处理.</li>
</ul>
<h4 id="学习策略实验"><a href="#学习策略实验" class="headerlink" title="学习策略实验"></a>学习策略实验</h4><p>poly学习策略：学习率计算公式为$lr_{base}*(1-\frac{iter}{max_iter})^{power}$，其中$power=0.9$。</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/CFmKmmf5Lf.png" alt="mark"></p>
<p>由上图结果，可以看出使用poly策略比固定的step策略效果要好。使用小批量batch_size=10(大了很吃显存，很吃硬件)，训练20K得到的效果最佳。</p>
<h4 id="ASPP模块实验"><a href="#ASPP模块实验" class="headerlink" title="ASPP模块实验"></a>ASPP模块实验</h4><p>ASPP的结构如下图所示，<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/f5BFeE0cb7.png" alt="mark"></p>
<p>并行以不同采样率的空洞卷积捕获不同大小的上下文信息。</p>
<p>下表报告了不同ASPP模块配置的实验结果：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/AG7KmDcB8D.png" alt="mark"></p>
<ul>
<li>baseline的LargeFOV： 具体结构如Fig7的(a)，在FC6上具有$r=12$的单分支</li>
<li>ASPP-S：具有并行四分支，空洞卷积采用较小的采样率$r={2,4,8,12}$</li>
<li>ASPP-L：具有并行四分支，空洞卷积采用较大的采样率$r={6,12,18,24}$</li>
</ul>
<p>可以看到，使用大采样率的ASPP模块效果要突出。</p>
<p>使用ASPP模块的可视化结果：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/Gbm43FclDe.png" alt="mark"></p>
<p>高采样率的ASPP更能捕获全局信息，相比之下分割更为合理。</p>
<h4 id="不同深度网络和多尺度处理实验"><a href="#不同深度网络和多尺度处理实验" class="headerlink" title="不同深度网络和多尺度处理实验"></a>不同深度网络和多尺度处理实验</h4><p>DeepLabv2主要是在ResNet上做实验，对比了几个方法：</p>
<ul>
<li>多尺度输入：以比例${ 0.5,0.75,1}$将输入送到DCNN，融合结果</li>
<li>在MS-COCO上预训练模型</li>
<li>训练期间随机缩放(0.5到1.5)输入图片做数据增强</li>
</ul>
<p><strong>模型处理方法的影响结果：</strong></p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/dKl1fcabK2.png" alt="mark"></p>
<p>多尺度带来了2.55%的提升。多种技巧融合得到了77.69%的结果。</p>
<p><strong>使用CRF后端处理的可视化效果：</strong></p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/9c7dFHGHKa.png" alt="mark"></p>
<p>CRF细化了分割结果，恢复一些错分的像素，同时也明确了一部分分割边界。</p>
<p><strong>DeepLabv2与其他先进模型相比：</strong></p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/haKHEfl5JE.png" alt="mark"></p>
<p>效果那自然是很好的~</p>
<p><strong>对比了ResNet101和VGG16做基础层对比：</strong></p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/F1a70LImD4.png" alt="mark"></p>
<p>采用ResNet101做基础层显著的提升了模型性能，基于ResNet101的DeepLab能够比VGG16更好的沿边界分割。</p>
<h3 id="PASCAL-Context"><a href="#PASCAL-Context" class="headerlink" title="PASCAL-Context"></a>PASCAL-Context</h3><p>在PASCAL-Context上基于VGG16和ResNet101不同变体的模型与其他先进模型的对比结果：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/LCBGdE3AGl.png" alt="mark"></p>
<p>采样多种技巧将最终结果提升到了45.7%。</p>
<p>可视化结果如下：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/ae12EH6gG0.png" alt="mark"></p>
<p>可以看到将更好的沿边界分割了。</p>
<h3 id="PASCAL-Person-Part"><a href="#PASCAL-Person-Part" class="headerlink" title="PASCAL-Person-Part"></a>PASCAL-Person-Part</h3><p>在PASCAL-Person-Part数据集上更关注于ResNet101模型，与其他模型对比结果：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/5CC8f3hhdB.png" alt="mark"></p>
<p>可视化结果如下：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/im967HG9IA.png" alt="mark"></p>
<h3 id="Cityscapes"><a href="#Cityscapes" class="headerlink" title="Cityscapes"></a>Cityscapes</h3><p>因为Cityscapes的数据分辨率较大，故先做下采样2倍，同时使用的各种技巧得到不错的实验结果：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/GDl79aALEC.png" alt="mark"></p>
<p>可视化结果如下：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/je0if5IHmi.png" alt="mark"></p>
<h3 id="失败案例"><a href="#失败案例" class="headerlink" title="失败案例"></a>失败案例</h3><p>论文给出了一些训练失败的案例，如下图：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/eb5hhdeKfF.png" alt="mark"></p>
<p>模型丢失了很多细节，并在CRF后丢失现象更严重了。</p>
<h2 id="Conclusion-1"><a href="#Conclusion-1" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>DeepLabv2将空洞卷积应用到密集的特征提取，进一步的提出了空洞卷积金字塔池化结构、并将DCNN和CRF融合用于细化分割结果。实验表明，DeepLabv2在多个数据集上表现优异，有着不错的分割性能。</p>
<hr>
<h2 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h2><p>代码参考的是<a href="https://github.com/DrSleep/tensorflow-deeplab-resnet" target="_blank" rel="external">github-TensorFlow版本</a>。<strong>注意这个代码没有实现CRF部分。</strong></p>
<p>这里模型使用的框架和前面的笔记<a href="http://blog.csdn.net/u011974639/article/details/79007588#t18" target="_blank" rel="external">ICNet代码框架</a>相同，可参考初期的NetWork设置详解。</p>
<h3 id="DeepLab-ResNet结构"><a href="#DeepLab-ResNet结构" class="headerlink" title="DeepLab_ResNet结构"></a>DeepLab_ResNet结构</h3><p>关于装饰器等定义在<a href="https://github.com/DrSleep/tensorflow-deeplab-resnet/blob/master/kaffe/tensorflow/network.py" target="_blank" rel="external">NetWork.py</a>中了，这里就不赘述。主要看<a href="https://github.com/DrSleep/tensorflow-deeplab-resnet/blob/master/deeplab_resnet/model.py" target="_blank" rel="external">DeepLab_ResNet模型定义</a>。</p>
<p>前面主要是ResNet101的变体结构定义：</p>
<h4 id="ResNet的前体"><a href="#ResNet的前体" class="headerlink" title="ResNet的前体"></a>ResNet的前体</h4><p>Reset基础层有两个常见的残差模块的变体：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/C8kDdJGHA0.png" alt="mark"></p>
<ul>
<li>左边是普通的残差单元： 辅分支通道直接恒等映射，主分支的前两个卷积都降通道数了，第三个卷积扩大回原通道数。这可以保持分割结果的同时大幅度减少计算量。</li>
<li>右边是特殊的残差单元：功能是增通道，即辅和主分支都增加通道；功能是增通道降采样，即辅分支卷积采用2步长，主分支第一个卷积采用2步长；功能包括空洞卷积的，将原$3×3$的普通卷积替换为不同采样率的空洞卷积即可。</li>
</ul>
<p>ResNet部分代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> kaffe.tensorflow <span class="keyword">import</span> Network</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeepLabResNetModel</span><span class="params">(Network)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setup</span><span class="params">(self, is_training, num_classes)</span>:</span></div><div class="line">        <span class="string">'''Network definition.</span></div><div class="line"><span class="string">        </span></div><div class="line"><span class="string">        Args:</span></div><div class="line"><span class="string">          is_training: whether to update the running mean and variance of the batch normalisation layer.</span></div><div class="line"><span class="string">                       If the batch size is small, it is better to keep the running mean and variance of </span></div><div class="line"><span class="string">                       the-pretrained model frozen.</span></div><div class="line"><span class="string">          num_classes: number of classes to predict (including background).</span></div><div class="line"><span class="string">        '''</span></div><div class="line">        (self.feed(<span class="string">'data'</span>)</div><div class="line">             .conv(<span class="number">7</span>, <span class="number">7</span>, <span class="number">64</span>, <span class="number">2</span>, <span class="number">2</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'conv1'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn_conv1'</span>)</div><div class="line">             .max_pool(<span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, name=<span class="string">'pool1'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res2a_branch1'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn2a_branch1'</span>))</div><div class="line"></div><div class="line">        (self.feed(<span class="string">'pool1'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">64</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res2a_branch2a'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn2a_branch2a'</span>)</div><div class="line">             .conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res2a_branch2b'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn2a_branch2b'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res2a_branch2c'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn2a_branch2c'</span>))</div><div class="line"></div><div class="line">        (self.feed(<span class="string">'bn2a_branch1'</span>, </div><div class="line">                   <span class="string">'bn2a_branch2c'</span>)</div><div class="line">             .add(name=<span class="string">'res2a'</span>)</div><div class="line">             .relu(name=<span class="string">'res2a_relu'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">64</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res2b_branch2a'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn2b_branch2a'</span>)</div><div class="line">             .conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res2b_branch2b'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn2b_branch2b'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res2b_branch2c'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn2b_branch2c'</span>))</div><div class="line"></div><div class="line">        (self.feed(<span class="string">'res2a_relu'</span>, </div><div class="line">                   <span class="string">'bn2b_branch2c'</span>)</div><div class="line">             .add(name=<span class="string">'res2b'</span>)</div><div class="line">             .relu(name=<span class="string">'res2b_relu'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">64</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res2c_branch2a'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn2c_branch2a'</span>)</div><div class="line">             .conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res2c_branch2b'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn2c_branch2b'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res2c_branch2c'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn2c_branch2c'</span>))</div><div class="line"></div><div class="line">        (self.feed(<span class="string">'res2b_relu'</span>, </div><div class="line">                   <span class="string">'bn2c_branch2c'</span>)</div><div class="line">             .add(name=<span class="string">'res2c'</span>)</div><div class="line">             .relu(name=<span class="string">'res2c_relu'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">512</span>, <span class="number">2</span>, <span class="number">2</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res3a_branch1'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn3a_branch1'</span>))</div><div class="line"></div><div class="line">        (self.feed(<span class="string">'res2c_relu'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">128</span>, <span class="number">2</span>, <span class="number">2</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res3a_branch2a'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn3a_branch2a'</span>)</div><div class="line">             .conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res3a_branch2b'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn3a_branch2b'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res3a_branch2c'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn3a_branch2c'</span>))</div><div class="line"></div><div class="line">        (self.feed(<span class="string">'bn3a_branch1'</span>, </div><div class="line">                   <span class="string">'bn3a_branch2c'</span>)</div><div class="line">             .add(name=<span class="string">'res3a'</span>)</div><div class="line">             .relu(name=<span class="string">'res3a_relu'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res3b1_branch2a'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn3b1_branch2a'</span>)</div><div class="line">             .conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res3b1_branch2b'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn3b1_branch2b'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res3b1_branch2c'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn3b1_branch2c'</span>))</div><div class="line"></div><div class="line">        (self.feed(<span class="string">'res3a_relu'</span>, </div><div class="line">                   <span class="string">'bn3b1_branch2c'</span>)</div><div class="line">             .add(name=<span class="string">'res3b1'</span>)</div><div class="line">             .relu(name=<span class="string">'res3b1_relu'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res3b2_branch2a'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn3b2_branch2a'</span>)</div><div class="line">             .conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res3b2_branch2b'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn3b2_branch2b'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res3b2_branch2c'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn3b2_branch2c'</span>))</div><div class="line"></div><div class="line">        (self.feed(<span class="string">'res3b1_relu'</span>, </div><div class="line">                   <span class="string">'bn3b2_branch2c'</span>)</div><div class="line">             .add(name=<span class="string">'res3b2'</span>)</div><div class="line">             .relu(name=<span class="string">'res3b2_relu'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res3b3_branch2a'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn3b3_branch2a'</span>)</div><div class="line">             .conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">128</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res3b3_branch2b'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn3b3_branch2b'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res3b3_branch2c'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn3b3_branch2c'</span>))</div><div class="line"></div><div class="line">        (self.feed(<span class="string">'res3b2_relu'</span>, </div><div class="line">                   <span class="string">'bn3b3_branch2c'</span>)</div><div class="line">             .add(name=<span class="string">'res3b3'</span>)</div><div class="line">             .relu(name=<span class="string">'res3b3_relu'</span>)</div><div class="line">             .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4a_branch1'</span>)</div><div class="line">             .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4a_branch1'</span>))</div></pre></td></tr></table></figure></p>
<p>上面一段代码示意图如下：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/IL1AGa6BdB.png" alt="mark"></p>
<p>总结一下，假设原输入为$(1024,1024,3)$</p>
<ul>
<li>先卷积+池化操作，提取特征映射<code>pool1</code>为$(256,256,64)$</li>
<li>经过一个增加通道的残差模块，得到<code>res2a_relu</code>为$(256,256,256)$，后面再跟两个普通的残差模块，得到<code>res2c_relu</code></li>
<li>再接一个升通道降采样的残差模块，得到<code>res3a_relu</code>为$(128,128,512)$，后面接三个普通的残差模块，得到<code>res3b3_relu</code></li>
</ul>
<p>这是ResNet变体初期的实现，到<code>res3b3_relu</code>输出的特征映射步幅已经为$\frac{1024}{128}=8$了，后面要配合带空洞卷积的残差模块了~</p>
<h4 id="ResNet的变体部分"><a href="#ResNet的变体部分" class="headerlink" title="ResNet的变体部分"></a>ResNet的变体部分</h4><p>DeepLabv2中使用的ResNet变体的前面部分与原ResNet模型基本一致，下面部分就是主要的改进部分了：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div></pre></td><td class="code"><pre><div class="line"><span class="string">'''与上面代码有重复  '''</span></div><div class="line">(self.feed(<span class="string">'res3b2_relu'</span>, </div><div class="line">           <span class="string">'bn3b3_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res3b3'</span>)</div><div class="line">     .relu(name=<span class="string">'res3b3_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4a_branch1'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4a_branch1'</span>))</div><div class="line">     </div><div class="line">(self.feed(<span class="string">'res3b3_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4a_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4a_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4a_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4a_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4a_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4a_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'bn4a_branch1'</span>, </div><div class="line">           <span class="string">'bn4a_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4a'</span>)</div><div class="line">     .relu(name=<span class="string">'res4a_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b1_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b1_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b1_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b1_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b1_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b1_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4a_relu'</span>, </div><div class="line">           <span class="string">'bn4b1_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b1'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b1_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b2_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b2_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b2_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b2_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b2_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b2_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b1_relu'</span>, </div><div class="line">           <span class="string">'bn4b2_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b2'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b2_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b3_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b3_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b3_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b3_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b3_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b3_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b2_relu'</span>, </div><div class="line">           <span class="string">'bn4b3_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b3'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b3_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b4_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b4_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b4_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b4_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b4_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b4_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b3_relu'</span>, </div><div class="line">           <span class="string">'bn4b4_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b4'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b4_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b5_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b5_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b5_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b5_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b5_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b5_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b4_relu'</span>, </div><div class="line">           <span class="string">'bn4b5_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b5'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b5_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b6_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b6_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b6_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b6_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b6_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b6_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b5_relu'</span>, </div><div class="line">           <span class="string">'bn4b6_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b6'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b6_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b7_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b7_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b7_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b7_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b7_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b7_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b6_relu'</span>, </div><div class="line">           <span class="string">'bn4b7_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b7'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b7_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b8_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b8_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b8_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b8_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b8_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b8_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b7_relu'</span>, </div><div class="line">           <span class="string">'bn4b8_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b8'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b8_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b9_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b9_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b9_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b9_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b9_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b9_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b8_relu'</span>, </div><div class="line">           <span class="string">'bn4b9_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b9'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b9_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b10_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b10_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b10_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b10_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b10_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b10_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b9_relu'</span>, </div><div class="line">           <span class="string">'bn4b10_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b10'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b10_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b11_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b11_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b11_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b11_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b11_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b11_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b10_relu'</span>, </div><div class="line">           <span class="string">'bn4b11_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b11'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b11_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b12_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b12_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b12_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b12_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b12_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b12_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b11_relu'</span>, </div><div class="line">           <span class="string">'bn4b12_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b12'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b12_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b13_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b13_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b13_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b13_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b13_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b13_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b12_relu'</span>, </div><div class="line">           <span class="string">'bn4b13_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b13'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b13_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b14_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b14_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b14_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b14_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b14_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b14_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b13_relu'</span>, </div><div class="line">           <span class="string">'bn4b14_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b14'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b14_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b15_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b15_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b15_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b15_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b15_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b15_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b14_relu'</span>, </div><div class="line">           <span class="string">'bn4b15_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b15'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b15_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b16_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b16_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b16_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b16_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b16_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b16_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b15_relu'</span>, </div><div class="line">           <span class="string">'bn4b16_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b16'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b16_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b17_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b17_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b17_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b17_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b17_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b17_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b16_relu'</span>, </div><div class="line">           <span class="string">'bn4b17_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b17'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b17_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b18_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b18_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b18_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b18_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b18_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b18_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b17_relu'</span>, </div><div class="line">           <span class="string">'bn4b18_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b18'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b18_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b19_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b19_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b19_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b19_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b19_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b19_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b18_relu'</span>, </div><div class="line">           <span class="string">'bn4b19_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b19'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b19_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b20_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b20_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b20_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b20_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b20_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b20_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b19_relu'</span>, </div><div class="line">           <span class="string">'bn4b20_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b20'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b20_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b21_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b21_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b21_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b21_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b21_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b21_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b20_relu'</span>, </div><div class="line">           <span class="string">'bn4b21_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b21'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b21_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b22_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b22_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b22_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn4b22_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res4b22_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn4b22_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b21_relu'</span>, </div><div class="line">           <span class="string">'bn4b22_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res4b22'</span>)</div><div class="line">     .relu(name=<span class="string">'res4b22_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2048</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res5a_branch1'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn5a_branch1'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res4b22_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res5a_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn5a_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">512</span>, <span class="number">4</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res5a_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn5a_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2048</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res5a_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn5a_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'bn5a_branch1'</span>, </div><div class="line">           <span class="string">'bn5a_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res5a'</span>)</div><div class="line">     .relu(name=<span class="string">'res5a_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res5b_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn5b_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">512</span>, <span class="number">4</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res5b_branch2b'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn5b_branch2b'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2048</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res5b_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn5b_branch2c'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res5a_relu'</span>, </div><div class="line">           <span class="string">'bn5b_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res5b'</span>)</div><div class="line">     .relu(name=<span class="string">'res5b_relu'</span>)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res5c_branch2a'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=<span class="string">'bn5c_branch2a'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, <span class="number">512</span>, <span class="number">4</span>, padding=<span class="string">'SAME'</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res5c_branch2b'</span>)</div><div class="line">     .batch_normalization(activation_fn=tf.nn.relu, name=<span class="string">'bn5c_branch2b'</span>, is_training=is_training)</div><div class="line">     .conv(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2048</span>, <span class="number">1</span>, <span class="number">1</span>, biased=<span class="keyword">False</span>, relu=<span class="keyword">False</span>, name=<span class="string">'res5c_branch2c'</span>)</div><div class="line">     .batch_normalization(is_training=is_training, activation_fn=<span class="keyword">None</span>, name=<span class="string">'bn5c_branch2c'</span>))</div><div class="line">     </div><div class="line">(self.feed(<span class="string">'res5b_relu'</span>, </div><div class="line">           <span class="string">'bn5c_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res5c'</span>)</div><div class="line">     .relu(name=<span class="string">'res5c_relu'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, num_classes, <span class="number">6</span>, padding=<span class="string">'SAME'</span>, relu=<span class="keyword">False</span>, name=<span class="string">'fc1_voc12_c0'</span>))</div></pre></td></tr></table></figure></p>
<p>上面一段代码示意图如下：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/5D80iJ71J2.png" alt="mark"></p>
<p>总结一下，输入<code>res3b3_relu</code>为$(128,128,512)$</p>
<ul>
<li>经过升通道带空洞卷积(r=2)的残差模块，得到<code>res4a_relu</code>为$(128,128,1024)$</li>
<li>再经过22个带空洞卷积(r=2)的残差模块，得到<code>res4b_relu</code>为$(128,128,1024)$</li>
<li>再接一个升通道带空洞卷积(r=4)的残差模块，得到<code>res5a_relu</code>为$(128,128,2048)$</li>
<li>后面接两个带空洞卷积(r=4)的的残差模块，得到<code>res5c_relu</code>为$(128,128,2048)$</li>
</ul>
<p>这是ResNet变体后部分的实现，到<code>res5c_relu</code>输出的特征映射步幅虽然是$\frac{1024}{128}=8$了，但是因为空洞卷积的使用，感受野扩大了很多，到这里，ResNet的部分算是结束了，下面就是ASPP模块了~</p>
<h3 id="ASPP模块"><a href="#ASPP模块" class="headerlink" title="ASPP模块"></a>ASPP模块</h3><p>DeepLabv2的ASPP和SPP模块很相似，主要就是在同一输入特征上应用不同采样率的空洞卷积，将结果融合到一起即可~<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">(self.feed(<span class="string">'res5b_relu'</span>, </div><div class="line">           <span class="string">'bn5c_branch2c'</span>)</div><div class="line">     .add(name=<span class="string">'res5c'</span>)</div><div class="line">     .relu(name=<span class="string">'res5c_relu'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, num_classes, <span class="number">6</span>, padding=<span class="string">'SAME'</span>, relu=<span class="keyword">False</span>, name=<span class="string">'fc1_voc12_c0'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res5c_relu'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, num_classes, <span class="number">12</span>, padding=<span class="string">'SAME'</span>, relu=<span class="keyword">False</span>, name=<span class="string">'fc1_voc12_c1'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res5c_relu'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, num_classes, <span class="number">18</span>, padding=<span class="string">'SAME'</span>, relu=<span class="keyword">False</span>, name=<span class="string">'fc1_voc12_c2'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'res5c_relu'</span>)</div><div class="line">     .atrous_conv(<span class="number">3</span>, <span class="number">3</span>, num_classes, <span class="number">24</span>, padding=<span class="string">'SAME'</span>, relu=<span class="keyword">False</span>, name=<span class="string">'fc1_voc12_c3'</span>))</div><div class="line"></div><div class="line">(self.feed(<span class="string">'fc1_voc12_c0'</span>, </div><div class="line">           <span class="string">'fc1_voc12_c1'</span>, </div><div class="line">           <span class="string">'fc1_voc12_c2'</span>, </div><div class="line">           <span class="string">'fc1_voc12_c3'</span>)</div><div class="line">     .add(name=<span class="string">'fc1_voc12'</span>))</div></pre></td></tr></table></figure></p>
<p>上面一段代码示意图如下：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/JlHL1c5Gek.png" alt="mark"></p>
<p>总结一下，输入<code>res5c_relu</code>为$(128,128,2048)$</p>
<ul>
<li>并行经过空洞卷积层，卷积核为$(3,3,num_class)$,取$num_class=21$</li>
<li>4个并行空洞卷积采样率为$r=6,12,18,24$</li>
<li>得到的输出作像素加，得到最终输出<code>fc1_voc12</code>为$(128,128,21)$</li>
</ul>
<p>这是ASPP模块的实现.</p>
<p>总得来说DeepLabv2中关于DCNN模型的实验还是很容易理解的(起码比前面的ICNet看起来简单多了)，关于CRF部分，现在TensorFlow1.4中有contrib的CRF，有兴趣的可以实验一下~</p>
<hr>
<hr>
<hr>
<h1 id="DeepLabv3"><a href="#DeepLabv3" class="headerlink" title="DeepLabv3"></a>DeepLabv3</h1><p>Rethinking Atrous Convolution for Semantic Image Segmentation</p>
<p>原文地址：<a href="https://arxiv.org/abs/1706.05587" target="_blank" rel="external">DeepLabv3</a></p>
<p>代码:</p>
<ul>
<li><a href="https://github.com/NanqingD/DeepLabV3-Tensorflow" target="_blank" rel="external">TensorFlow</a></li>
</ul>
<hr>
<h2 id="Abstract-2"><a href="#Abstract-2" class="headerlink" title="Abstract"></a>Abstract</h2><p>DeepLabv3进一步探讨空洞卷积，这是一个在语义分割任务中：可以调整滤波器视野、控制卷积神经网络计算的特征响应分辨率的强大工具。为了解决多尺度下的目标分割问题，我们设计了空洞卷积级联或不同采样率空洞卷积并行架构。此外，我们强调了ASPP(Atrous Spatial Pyramid Pooling)模块，该模块可以在获取多个尺度上卷积特征，进一步提升性能。同时，我们分享了实施细节和训练方法，此次提出的DeepLabv3相比先前的版本有显著的效果提升，在PASCAL VOC 2012上获得了先进的性能。</p>
<h2 id="Introduction-2"><a href="#Introduction-2" class="headerlink" title="Introduction"></a>Introduction</h2><p>对于语义分割任务，在应用深度卷积神经网络中的有两个挑战：</p>
<ul>
<li>第一个挑战：连续池化和下采样，让高层特征具有局部图像变换的内在不变性，这允许DCNN学习越来越抽象的特征表示。但同时引起的特征分辨率下降，会妨碍密集的定位预测任务，因为这需要详细的空间信息。DeepLabv3系列解决这一问题的办法是<strong>使用空洞卷积</strong>(前两个版本会使用CRF细化分割结果)，这允许我们可以保持参数量和计算量的同时提升计算特征响应的分辨率，从而获得更多的上下文。</li>
</ul>
<ul>
<li><p>第二个挑战：多尺度目标的存在。现有多种处理多尺度目标的方法，我们主要考虑4种，如下图：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/EDflDAH02J.png" alt="mark"></p>
<ul>
<li>a. Image Pyramid: 将输入图片放缩成不同比例，分别应用在DCNN上，将预测结果融合得到最终输出</li>
<li>b. Encoder-Decoder: 利用Encoder阶段的多尺度特征，运用到Decoder阶段上恢复空间分辨率(代表工作有FCN、SegNet、PSPNet等工作)</li>
<li>c. Deeper w. Atrous Convolution: 在原始模型的顶端增加额外的模块，例如DenseCRF，捕捉像素间长距离信息</li>
<li>d. Spatial Pyramid Pooling: 空间金字塔池化具有不同采样率和多种视野的卷积核，能够以多尺度捕捉对象</li>
</ul>
</li>
</ul>
<p>DeepLabv3的主要贡献在于：</p>
<ul>
<li><p>本文重新讨论了空洞卷积的使用，这让我们在级联模块和空间金字塔池化的框架下，能够获取更大的感受野从而获取多尺度信息。</p>
</li>
<li><p>改进了ASPP模块：由不同采样率的空洞卷积和BN层组成，我们尝试以级联或并行的方式布局模块。</p>
</li>
<li><p>讨论了一个重要问题：使用大采样率的$3×3$的空洞卷积，因为图像边界响应无法捕捉远距离信息，会退化为1×1的卷积, 我们建议将图像级特征融合到ASPP模块中。 </p>
</li>
<li><p>阐述了训练细节并分享了训练经验，论文提出的”DeepLabv3”改进了以前的工作，获得了很好的结果</p>
</li>
</ul>
<h2 id="Related-Work-2"><a href="#Related-Work-2" class="headerlink" title="Related Work"></a>Related Work</h2><p>现有多个工作表明<strong>全局特征或上下文之间的互相作用有助于做语义分割</strong>，我们讨论四种不同类型利用上下文信息做语义分割的全卷积网络。</p>
<ul>
<li><p>图像金字塔(Image pyramid)： 通常使用共享权重的模型，适用于多尺度的输入。<strong>小尺度的输入响应控制语义，大尺寸的输入响应控制细节</strong>。通过拉布拉斯金字塔对输入变换成多尺度，传入DCNN，融合输出。这类的缺点是：<strong>因为GPU存储器的限制，对于更大/更深的模型不方便扩展。通常应用于推断阶段</strong>。</p>
</li>
<li><p>编码器-解码器(Encoder-decoder)： <strong>编码器的高层次的特征容易捕获更长的距离信息，在解码器阶段使用编码器阶段的信息帮助恢复目标的细节和空间维度。</strong>例如SegNet利用下采样的池化索引作为上采样的指导；U-Net增加了编码器部分的特征跳跃连接到解码器；RefineNet等证明了Encoder-Decoder结构的有效性。</p>
</li>
<li><p>上下文模块(Context module)：包含了额外的模块用于级联编码长距离的上下文。一种有效的方法是DenseCRF并入DCNN中，共同训练DCNN和CRF。</p>
</li>
<li><p>空间金字塔池化(Spatial pyramid pooling)：<strong>采用空间金字塔池化可以捕捉多个层次的上下文。</strong>在ParseNet中从不同图像等级的特征中获取上下文信息；DeepLabv2提出ASPP，以不同采样率的并行空洞卷积捕捉多尺度信息。最近PSPNet在不同网格尺度上执行空间池化，并在多个数据集上获得优异的表现。还有其他基于LSTM方法聚合全局信息。</p>
</li>
</ul>
<p>我们的工作主要探讨空洞卷积作为上下文模块和一个空间金字塔池化的工具，这适用于任何网络。具体来说，我们取ResNet最后一个block，复制多个级联起来，送入到ASPP模块后。我们通过实验发现使用BN层有利于训练过程，为了进一步捕获全局上下文，我们建议在ASPP上融入图像级特征.</p>
<hr>
<h2 id="Method-1"><a href="#Method-1" class="headerlink" title="Method"></a>Method</h2><h3 id="空洞卷积应用于密集的特征提取"><a href="#空洞卷积应用于密集的特征提取" class="headerlink" title="空洞卷积应用于密集的特征提取"></a>空洞卷积应用于密集的特征提取</h3><p>这在DeepLabv1和DeepLabv2都已经讲过，这里不详解了~</p>
<h3 id="深层次的空洞卷积"><a href="#深层次的空洞卷积" class="headerlink" title="深层次的空洞卷积"></a>深层次的空洞卷积</h3><p>我们首先探讨将空洞卷积应用在级联模块。具体来说，我们取ResNet中最后一个block，在下图中为block4，并在其后面增加级联模块。</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/G0acji3Cmd.png" alt="mark"></p>
<ul>
<li><p>上图(a)所示，整体图片的信息总结到后面非常小的特征映射上，但实验证明这是不利于语义分割的。如下图：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/c6l0L60AKf.png" alt="mark"><br>使用步幅越长的特征映射，得到的结果反倒会差，结果最好的out_stride = 8 需要占用较多的存储空间。因为连续的下采样会降低特征映射的分辨率，细节信息被抽取，这对语义分割是有害的。</p>
</li>
<li><p>上图(b)所示，可使用不同采样率的空洞卷积保持输出步幅的为out_stride = 16.这样不增加参数量和计算量同时有效的缩小了步幅。</p>
</li>
</ul>
<p>###　Atrous Spatial Pyramid Pooling</p>
<p>对于在DeepLabv2中提出的ASPP模块，其在特征顶部映射图并行使用了四种不同采样率的空洞卷积。这表明以不同尺度采样是有效的，我们在DeepLabv3中向ASPP中添加了BN层。不同采样率的空洞卷积可以有效的捕获多尺度信息，但是，我们发现随着采样率的增加，滤波器的有效权重(权重有效的应用在特征区域，而不是填充0)逐渐变小。如下图所示：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/hhJ1L9g27m.png" alt="mark"></p>
<p>当我们不同采样率的$3×3$卷积核应用在$65×65$的特征映射上，当采样率接近特征映射大小时，$3×3$的滤波器不是捕捉全图像的上下文，而是退化为简单的$1×1$滤波器，只有滤波器中心点的权重起了作用。</p>
<p>为了克服这个问题，我们考虑使用图片级特征。具体来说，我们在模型最后的特征映射上应用全局平均，将结果经过$1×1$的卷积，再双线性上采样得到所需的空间维度。最终，我们改进的ASPP包括：</p>
<ul>
<li>一个$1×1$卷积和三个$3×3$的采样率为$rates = {6,12,18}$的空洞卷积，滤波器数量为256，包含BN层。针对output_stride=16的情况。如下图(a)部分<code>Atrous Spatial Pyramid Pooling</code></li>
<li>图像级特征，即将特征做全局平均池化，经过卷积，再融合。如下图(b)部分<code>Image Pooling</code>.</li>
</ul>
<p>改进后的ASPP模块如下图所示：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/J9I9mBlF0C.png" alt="mark"></p>
<p>注意当output_stride=8时，加倍了采样率。所有的特征通过$1×1$级联到一起，生成最终的分数.</p>
<h2 id="Experiment-2"><a href="#Experiment-2" class="headerlink" title="Experiment"></a>Experiment</h2><p>采用的是预训练的ResNet为基础层，并配合使用了空洞卷积控制输出步幅。因为输出步幅output_stride(定义为输入图像的分辨率与最终输出分辨率的比值)。当我们输出步幅为8时，原ResNet的最后两个block包含的空洞卷积的采样率为$r=2$和$r=4$。</p>
<p>模型的训练设置：</p>
<table>
<thead>
<tr>
<th>部分</th>
<th>设置</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据集</td>
<td>PASCAL VOC 2012</td>
</tr>
<tr>
<td>工具</td>
<td>TensorFlow</td>
</tr>
<tr>
<td>裁剪尺寸</td>
<td>采样513大小的裁剪尺寸</td>
</tr>
<tr>
<td>学习率策略</td>
<td>采用poly策略， 在初始学习率基础上，乘以$(1-\frac{iter}{max_iter})^{power}$,其中$power=0.9$</td>
</tr>
<tr>
<td><strong>BN层策略</strong></td>
<td>当output_stride=16时，我们采用batchsize=16，同时BN层的参数做参数衰减0.9997。<br>在增强的数据集上，以初始学习率0.007训练30K后，冻结BN层参数。<br>采用output_stride=8时，再使用初始学习率0.001训练30K。<br>训练output_stride=16比output_stride=8要快很多，因为中间的特征映射在空间上小的四倍。但因为output_stride=16在特征映射上粗糙是牺牲了精度。</td>
</tr>
<tr>
<td><strong>上采样策略</strong></td>
<td>在先前的工作上，<br>我们是将最终的输出与GroundTruth下采样8倍做比较<br>现在我们发现保持GroundTruth更重要，故我们是将最终的输出上采样8倍与完整的GroundTruth比较。</td>
</tr>
</tbody>
</table>
<h3 id="Going-Deeper-with-Atrous-Convolution实验"><a href="#Going-Deeper-with-Atrous-Convolution实验" class="headerlink" title="Going Deeper with Atrous Convolution实验"></a>Going Deeper with Atrous Convolution实验</h3><p>我们首先试试级联使用多个带空洞卷积的block模块。</p>
<ul>
<li><p><strong>ResNet50</strong>：如下图，我们探究输出步幅的影响，当输出步幅为256时，由于严重的信号抽取，性能大大的下降了。<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/hADC1i17Hk.png" alt="mark"><br>而当我们使用不同采样率的空洞卷积，结果大大的上升了，这表现在语义分割中使用空洞卷积的必要性。</p>
</li>
<li><p><strong>ResNet50 vs. ResNet101</strong>: 用更深的模型，并改变级联模块的数量。如下图，当block增加性能也随之增加。<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/m327dE1c8m.png" alt="mark"></p>
</li>
<li><p><strong>Multi-grid</strong>： 我们使用的变体残差模块，采用Multi-gird策略，即主分支的三个卷积都使用空洞卷积，采样率设置Multi-gird策略。按照如下图：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/4lbc7h08f9.png" alt="mark"></p>
<ul>
<li>应用不同策略通常比单倍数$(r_1,r_2,r_3)=(1,1,1)$效果要好</li>
<li>简单的提升倍数是无效的$(r_1,r_2,r_3)=(2,2,2)$</li>
<li>最好的随着网络的深入提升性能.即block7下$(r_1,r_2,r_3)=(1,2,1)$</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Inference strategy on val set</strong>：<br>推断期间使用output_stride = 8，有着更丰富的细节内容:<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/kII63g7c9D.png" alt="mark"></li>
</ul>
<h3 id="Atrous-Spatial-Pyramid-Pooling实验"><a href="#Atrous-Spatial-Pyramid-Pooling实验" class="headerlink" title="Atrous Spatial Pyramid Pooling实验"></a>Atrous Spatial Pyramid Pooling实验</h3><ul>
<li>ASPP模块相比以前增加了BN层，对比multi-grid策略和图片层级特征提升实验结果：</li>
</ul>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/08GkcLGKFE.png" alt="mark"></p>
<ul>
<li><strong>Inference strategy on val set</strong>：<br>推断期间使用output_stride = 8，有着更丰富的细节内容，采用多尺度输入和翻转，性能进一步提升了:<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/B8j8m02K1h.png" alt="mark"></li>
</ul>
<h3 id="在PASCAL-VOC-2012上表现："><a href="#在PASCAL-VOC-2012上表现：" class="headerlink" title="在PASCAL VOC 2012上表现："></a>在PASCAL VOC 2012上表现：</h3><p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/iad2fCbded.png" alt="mark"></p>
<h3 id="Cityscapes表现"><a href="#Cityscapes表现" class="headerlink" title="Cityscapes表现"></a>Cityscapes表现</h3><p>多种技巧配置结果：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/6ha93fJd5G.png" alt="mark"></p>
<p>与其他模型相比：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/fDfFha2J6f.png" alt="mark"></p>
<h3 id="其他参数的影响"><a href="#其他参数的影响" class="headerlink" title="其他参数的影响"></a>其他参数的影响</h3><ul>
<li>上采样策略和裁剪大小和BN层的影响：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/Jc54jAJEK0.png" alt="mark"></li>
</ul>
<ul>
<li>不同batchsize的影响：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/80b79b199B.png" alt="mark"></li>
</ul>
<ul>
<li>不同评估步幅的影响：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180123/7jC81BBe4m.png" alt="mark"></li>
</ul>
<h2 id="Conclusion-2"><a href="#Conclusion-2" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>DeepLabv3重点探讨了空洞卷积的使用，同时改进了ASPP模块，便于更好的捕捉多尺度上下文。</p>
<hr>
<h2 id="代码分析-1"><a href="#代码分析-1" class="headerlink" title="代码分析"></a>代码分析</h2><p>因为没找到官方的代码，在github上找了一个<a href="https://github.com/NanqingD/DeepLabV3-Tensorflow" target="_blank" rel="external">DeepLabV3-TensorFlow</a>版本.</p>
<h3 id="训练脚本分析"><a href="#训练脚本分析" class="headerlink" title="训练脚本分析"></a>训练脚本分析</h3><p>先找到<a href="https://github.com/NanqingD/DeepLabV3-Tensorflow/blob/master/train_voc12.py" target="_blank" rel="external">train_voc12.py</a>训练文件。</p>
<p>找到关键的main方法：</p>
<h4 id="创建训练模型-amp-计算loss"><a href="#创建训练模型-amp-计算loss" class="headerlink" title="创建训练模型 &amp; 计算loss"></a>创建训练模型 &amp; 计算loss</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line">    <span class="string">"""创建模型 and 准备训练."""</span></div><div class="line">    h = args.input_size</div><div class="line">    w = args.input_size</div><div class="line">    input_size = (h, w)</div><div class="line">    </div><div class="line">    <span class="comment"># 设置随机种子</span></div><div class="line">    tf.set_random_seed(args.random_seed)</div><div class="line">    </div><div class="line">    <span class="comment"># 创建线程队列，准备数据</span></div><div class="line">    coord = tf.train.Coordinator()</div><div class="line"></div><div class="line">    <span class="comment"># 读取数据</span></div><div class="line">    image_batch, label_batch = read_data(is_training=<span class="keyword">True</span>)</div><div class="line">    </div><div class="line">    <span class="comment"># 创建训练模型</span></div><div class="line">    net, end_points = deeplabv3(image_batch,</div><div class="line">                                num_classes=args.num_classes,</div><div class="line">                                depth=args.num_layers,</div><div class="line">                                is_training=<span class="keyword">True</span>,</div><div class="line">                                )</div><div class="line">    <span class="comment"># 对于小的batchsize,保持BN layers的统计参数更佳(即冻结预训练模型的BN参数)</span></div><div class="line">    <span class="comment"># If is_training=True, 统计参数在训练期间会被更新</span></div><div class="line">    <span class="comment"># 注意的是：即使is_training=False ，BN参数gamma (scale) and beta (offset) 也会更新</span></div><div class="line"></div><div class="line">    <span class="comment"># 取出模型预测值</span></div><div class="line">    raw_output = end_points[<span class="string">'resnet&#123;&#125;/logits'</span>.format(args.num_layers)]</div><div class="line">    </div><div class="line">    <span class="comment"># Which variables to load. Running means and variances are not trainable,</span></div><div class="line">    <span class="comment"># thus all_variables() should be restored.</span></div><div class="line">    restore_var = [v <span class="keyword">for</span> v <span class="keyword">in</span> tf.global_variables() <span class="keyword">if</span> <span class="string">'fc'</span> <span class="keyword">not</span> <span class="keyword">in</span> v.name </div><div class="line">        <span class="keyword">or</span> <span class="keyword">not</span> args.not_restore_last]</div><div class="line">    <span class="keyword">if</span> args.freeze_bn:</div><div class="line">        all_trainable = [v <span class="keyword">for</span> v <span class="keyword">in</span> tf.trainable_variables() <span class="keyword">if</span> <span class="string">'beta'</span> <span class="keyword">not</span> <span class="keyword">in</span> </div><div class="line">            v.name <span class="keyword">and</span> <span class="string">'gamma'</span> <span class="keyword">not</span> <span class="keyword">in</span> v.name]</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        all_trainable = [v <span class="keyword">for</span> v <span class="keyword">in</span> tf.trainable_variables()]</div><div class="line">    conv_trainable = [v <span class="keyword">for</span> v <span class="keyword">in</span> all_trainable <span class="keyword">if</span> <span class="string">'fc'</span> <span class="keyword">not</span> <span class="keyword">in</span> v.name] </div><div class="line">    </div><div class="line">    <span class="comment"># 上采样logits输出，取代ground truth下采样</span></div><div class="line">    raw_output_up = tf.image.resize_bilinear(raw_output, [h, w]) <span class="comment"># 双线性插值放大到原大小</span></div><div class="line"></div><div class="line">    <span class="comment"># Predictions: 忽略标签中大于或等于n_classes的值</span></div><div class="line">    label_proc = tf.squeeze(label_batch) <span class="comment"># 删除数据标签tensor的shape中维度值为1</span></div><div class="line">    mask = label_proc &lt;= args.num_classes <span class="comment"># 忽略标签中大于或等于n_classes的值</span></div><div class="line">    seg_logits = tf.boolean_mask(raw_output_up, mask)  <span class="comment">#取出预测值中感兴趣的mask</span></div><div class="line">    seg_gt = tf.boolean_mask(label_proc, mask) <span class="comment"># 取出数据标签中标注的mask(感兴趣的mask)</span></div><div class="line">    seg_gt = tf.cast(seg_gt, tf.int32)  <span class="comment"># 转换一下数据类型        </span></div><div class="line">                                                  </div><div class="line">    <span class="comment"># 逐像素做softmax loss.</span></div><div class="line">    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=seg_logits,</div><div class="line">        labels=seg_gt)</div><div class="line">    seg_loss = tf.reduce_mean(loss)</div><div class="line">    seg_loss_sum = tf.summary.scalar(<span class="string">'loss/seg'</span>, seg_loss) <span class="comment"># TensorBoard记录</span></div><div class="line">    </div><div class="line">    <span class="comment"># 增加正则化损失</span></div><div class="line">    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)</div><div class="line">    reg_loss = tf.add_n(reg_losses)</div><div class="line">    reg_loss_sum = tf.summary.scalar(<span class="string">'loss/reg'</span>, reg_loss)</div><div class="line">    </div><div class="line">    tot_loss = seg_loss + reg_loss</div><div class="line">    tot_loss_sum = tf.summary.scalar(<span class="string">'loss/tot'</span>, tot_loss)</div><div class="line"></div><div class="line">    seg_pred = tf.argmax(seg_logits, axis=<span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="comment">#  计算MIOU </span></div><div class="line">    train_mean_iou, train_update_mean_iou = streaming_mean_iou(seg_pred, </div><div class="line">        seg_gt, args.num_classes, name=<span class="string">"train_iou"</span>)  </div><div class="line">    </div><div class="line">    train_iou_sum = tf.summary.scalar(<span class="string">'accuracy/train_mean_iou'</span>, </div><div class="line">        train_mean_iou)</div></pre></td></tr></table></figure>
<p>关于streaming_mean_iou方法代码见<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/metrics/python/ops/metric_ops.py" target="_blank" rel="external">metric_ops.py</a>，该方法用于计算每步的平均交叉点(mIOU),即先计算每个类别的IOU，再平均到各个类上。</p>
<p>IOU的计算定义如下：$$IOU = \frac{true_positive}{true_positive+false_positive+false_negative}$$该方法返回一个<code>update_op</code>操作用于估计数据流上的度量，更新变量并返回<code>mean_iou</code>.</p>
<p>上面代码初始化了DeepLabv3模型，并取出模型输出，计算了loss，并计算了mIOU.</p>
<h4 id="训练参数设置"><a href="#训练参数设置" class="headerlink" title="训练参数设置"></a>训练参数设置</h4><p>这里学习率没有使用poly策略，该github说学习率设置0.00001效果更好点~</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 初始化训练参数</span></div><div class="line">train_initializer = tf.variables_initializer(var_list=tf.get_collection(</div><div class="line">    tf.GraphKeys.LOCAL_VARIABLES, scope=<span class="string">"train_iou"</span>))</div><div class="line"></div><div class="line"><span class="comment"># 定义 loss and 优化参数.</span></div><div class="line"><span class="comment"># 这里学习率没采用poly策略  </span></div><div class="line">base_lr = tf.constant(args.learning_rate)</div><div class="line">step_ph = tf.placeholder(dtype=tf.float32, shape=())</div><div class="line"><span class="comment"># learning_rate = tf.scalar_mul(base_lr, </span></div><div class="line"><span class="comment">#    tf.pow((1 - step_ph / args.num_steps), args.power))</span></div><div class="line">learning_rate = base_lr</div><div class="line">lr_sum = tf.summary.scalar(<span class="string">'params/learning_rate'</span>, learning_rate)</div><div class="line"></div><div class="line">train_sum_op = tf.summary.merge([seg_loss_sum, reg_loss_sum, </div><div class="line">    tot_loss_sum, train_iou_sum, lr_sum])</div></pre></td></tr></table></figure>
<h4 id="创建交叉验证模型，并设置输出值"><a href="#创建交叉验证模型，并设置输出值" class="headerlink" title="创建交叉验证模型，并设置输出值"></a>创建交叉验证模型，并设置输出值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 交叉验证模型</span></div><div class="line">image_batch_val, label_batch_val = read_data(is_training=<span class="keyword">False</span>)</div><div class="line">_, end_points_val = deeplabv3(image_batch_val,</div><div class="line">                              num_classes=args.num_classes,</div><div class="line">                              depth=args.num_layers,</div><div class="line">                              reuse=<span class="keyword">True</span>,</div><div class="line">                              is_training=<span class="keyword">False</span>,</div><div class="line">                              )</div><div class="line">raw_output_val = end_points_val[<span class="string">'resnet&#123;&#125;/logits'</span>.format(args.num_layers)] <span class="comment"># 交叉验证输出</span></div><div class="line">nh, nw = tf.shape(image_batch_val)[<span class="number">1</span>], tf.shape(image_batch_val)[<span class="number">2</span>]</div><div class="line"></div><div class="line">seg_logits_val = tf.image.resize_bilinear(raw_output_val, [nh, nw])</div><div class="line">seg_pred_val = tf.argmax(seg_logits_val, axis=<span class="number">3</span>)</div><div class="line">seg_pred_val = tf.expand_dims(seg_pred_val, <span class="number">3</span>)</div><div class="line">seg_pred_val = tf.reshape(seg_pred_val, [<span class="number">-1</span>,])</div><div class="line"></div><div class="line">seg_gt_val = tf.cast(label_batch_val, tf.int32)</div><div class="line">seg_gt_val = tf.reshape(seg_gt_val, [<span class="number">-1</span>,])</div><div class="line">mask_val = seg_gt_val &lt;= args.num_classes - <span class="number">1</span></div><div class="line"></div><div class="line">seg_pred_val = tf.boolean_mask(seg_pred_val, mask_val)</div><div class="line">seg_gt_val = tf.boolean_mask(seg_gt_val, mask_val)</div><div class="line"></div><div class="line">val_mean_iou, val_update_mean_iou = streaming_mean_iou(seg_pred_val, </div><div class="line">    seg_gt_val, num_classes=args.num_classes, name=<span class="string">"val_iou"</span>)        </div><div class="line">val_iou_sum = tf.summary.scalar(<span class="string">'accuracy/val_mean_iou'</span>, val_mean_iou)</div></pre></td></tr></table></figure>
<h4 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div></pre></td><td class="code"><pre><div class="line">val_initializer = tf.variables_initializer(var_list=tf.get_collection(</div><div class="line">    tf.GraphKeys.LOCAL_VARIABLES, scope=<span class="string">"val_iou"</span>))</div><div class="line">test_sum_op = tf.summary.merge([val_iou_sum])</div><div class="line">global_step = tf.train.get_or_create_global_step()</div><div class="line"></div><div class="line">opt = tf.train.MomentumOptimizer(learning_rate, args.momentum)</div><div class="line">grads_conv = tf.gradients(tot_loss, conv_trainable)</div><div class="line"><span class="comment"># train_op = opt.apply_gradients(zip(grads_conv, conv_trainable))</span></div><div class="line">train_op = slim.learning.create_train_op(</div><div class="line">    tot_loss, opt,</div><div class="line">    global_step=global_step,</div><div class="line">    variables_to_train=conv_trainable,</div><div class="line">    summarize_gradients=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="comment"># Set up tf session and initialize variables. </span></div><div class="line">config = tf.ConfigProto()</div><div class="line">config.gpu_options.allow_growth = <span class="keyword">True</span></div><div class="line">sess = tf.Session(config=config)</div><div class="line"></div><div class="line">sess.run(tf.global_variables_initializer())</div><div class="line">sess.run(tf.local_variables_initializer())</div><div class="line"></div><div class="line"><span class="comment"># Saver for storing checkpoints of the model.</span></div><div class="line">saver = tf.train.Saver(var_list=tf.global_variables(), max_to_keep=<span class="number">20</span>)</div><div class="line"></div><div class="line"><span class="comment"># 如果有checkpoint则加载</span></div><div class="line"><span class="keyword">if</span> args.ckpt &gt; <span class="number">0</span> <span class="keyword">or</span> args.restore_from <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">    loader = tf.train.Saver(var_list=restore_var)</div><div class="line">    load(loader, sess, args.snapshot_dir)</div><div class="line"></div><div class="line"><span class="comment"># 开始线程队列</span></div><div class="line">threads = tf.train.start_queue_runners(coord=coord, sess=sess)</div><div class="line"></div><div class="line"><span class="comment"># tf.get_default_graph().finalize()</span></div><div class="line">summary_writer = tf.summary.FileWriter(args.snapshot_dir,</div><div class="line">                                       sess.graph)</div><div class="line"></div><div class="line"><span class="comment"># 迭代训练</span></div><div class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(args.ckpt, args.num_steps):</div><div class="line">    start_time = time.time()</div><div class="line">    feed_dict = &#123; step_ph : step &#125;</div><div class="line">    tot_loss_float, seg_loss_float, reg_loss_float, _, lr_float, _,train_summary = sess.run([tot_loss, seg_loss, reg_loss, train_op,</div><div class="line">        learning_rate, train_update_mean_iou, train_sum_op], </div><div class="line">        feed_dict=feed_dict)</div><div class="line">    train_mean_iou_float = sess.run(train_mean_iou)</div><div class="line">    duration = time.time() - start_time</div><div class="line">    sys.stdout.write(<span class="string">'step &#123;:d&#125;, tot_loss = &#123;:.6f&#125;, seg_loss = &#123;:.6f&#125;, '</span> \</div><div class="line">        <span class="string">'reg_loss = &#123;:.6f&#125;, mean_iou = &#123;:.6f&#125;, lr: &#123;:.6f&#125;(&#123;:.3f&#125;'</span> \</div><div class="line">        <span class="string">'sec/step)\n'</span>.format(step, tot_loss_float, seg_loss_float,</div><div class="line">         reg_loss_float, train_mean_iou_float, lr_float, duration)</div><div class="line">        )</div><div class="line">    sys.stdout.flush()</div><div class="line"></div><div class="line">    <span class="keyword">if</span> step % args.save_pred_every == <span class="number">0</span> <span class="keyword">and</span> step &gt; args.ckpt:</div><div class="line">        summary_writer.add_summary(train_summary, step)</div><div class="line">        sess.run(val_initializer)</div><div class="line">        <span class="keyword">for</span> val_step <span class="keyword">in</span> range(NUM_VAL<span class="number">-1</span>):</div><div class="line">            _, test_summary = sess.run([val_update_mean_iou, test_sum_op],</div><div class="line">            feed_dict=feed_dict)</div><div class="line">        </div><div class="line">        summary_writer.add_summary(test_summary, step)</div><div class="line">        val_mean_iou_float= sess.run(val_mean_iou)</div><div class="line"></div><div class="line">        save(saver, sess, args.snapshot_dir, step)</div><div class="line">        sys.stdout.write(<span class="string">'step &#123;:d&#125;, train_mean_iou: &#123;:.6f&#125;, '</span> \</div><div class="line">            <span class="string">'val_mean_iou: &#123;:.6f&#125;\n'</span>.format(step, train_mean_iou_float, </div><div class="line">            val_mean_iou_float))</div><div class="line">        sys.stdout.flush()</div><div class="line">        sess.run(train_initializer)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> coord.should_stop():</div><div class="line">        coord.request_stop()</div><div class="line">        coord.join(threads)</div></pre></td></tr></table></figure>
<h3 id="模型分析"><a href="#模型分析" class="headerlink" title="模型分析"></a>模型分析</h3><p>上面看完了训练脚本，下面看看DeepLabv3的模型定义脚本<a href="https://github.com/NanqingD/DeepLabV3-Tensorflow/blob/master/libs/nets/deeplabv3.py" target="_blank" rel="external">libs.nets.deeplabv3.py</a>.</p>
<h4 id="deeplabv3中ResNet变体"><a href="#deeplabv3中ResNet变体" class="headerlink" title="deeplabv3中ResNet变体"></a>deeplabv3中ResNet变体</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">deeplabv3</span><span class="params">(inputs,</span></span></div><div class="line"><span class="function"><span class="params">              num_classes,</span></span></div><div class="line"><span class="function"><span class="params">              depth=<span class="number">50</span>,</span></span></div><div class="line"><span class="function"><span class="params">              aspp=True,</span></span></div><div class="line"><span class="function"><span class="params">              reuse=None,</span></span></div><div class="line"><span class="function"><span class="params">              is_training=True)</span>:</span></div><div class="line">  <span class="string">"""DeepLabV3</span></div><div class="line"><span class="string">  Args:</span></div><div class="line"><span class="string">    inputs: A tensor of size [batch, height, width, channels].</span></div><div class="line"><span class="string">    depth: ResNet的深度 一般为101或51.</span></div><div class="line"><span class="string">    aspp: 是否使用ASPP module, if True, 使用4 blocks with multi_grid=(1,2,4), if False, 使用7 blocks with multi_grid=(1,2,1).</span></div><div class="line"><span class="string">    reuse: 模型参数重用(验证会重用训练的模型参数)</span></div><div class="line"><span class="string">  Returns:</span></div><div class="line"><span class="string">    net: A rank-4 tensor of size [batch, height_out, width_out, channels_out].</span></div><div class="line"><span class="string">    end_points: 模型的组合</span></div><div class="line"><span class="string">  """</span></div><div class="line"></div><div class="line">  <span class="keyword">if</span> aspp:</div><div class="line">    multi_grid = (<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>)</div><div class="line">  <span class="keyword">else</span>:</div><div class="line">    multi_grid = (<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</div><div class="line">  scope =<span class="string">'resnet&#123;&#125;'</span>.format(depth)</div><div class="line">  <span class="keyword">with</span> tf.variable_scope(scope, [inputs], reuse=reuse) <span class="keyword">as</span> sc:</div><div class="line">    end_points_collection = sc.name + <span class="string">'_end_points'</span></div><div class="line">    <span class="keyword">with</span> slim.arg_scope(resnet_arg_scope(weight_decay=args.weight_decay, </div><div class="line">      batch_norm_decay=args.bn_weight_decay)):</div><div class="line">      <span class="keyword">with</span> slim.arg_scope([slim.conv2d, bottleneck, bottleneck_hdc],</div><div class="line">                          outputs_collections=end_points_collection):</div><div class="line">        <span class="keyword">with</span> slim.arg_scope([slim.batch_norm], is_training=is_training):</div><div class="line">          net = inputs</div><div class="line">          net = resnet_utils.conv2d_same(net, <span class="number">64</span>, <span class="number">7</span>, stride=<span class="number">2</span>, scope=<span class="string">'conv1'</span>)</div><div class="line">          net = slim.max_pool2d(net, [<span class="number">3</span>, <span class="number">3</span>], stride=<span class="number">2</span>, scope=<span class="string">'pool1'</span>)</div><div class="line"></div><div class="line">          <span class="keyword">with</span> tf.variable_scope(<span class="string">'block1'</span>, [net]) <span class="keyword">as</span> sc:</div><div class="line">            base_depth = <span class="number">64</span></div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):</div><div class="line">              <span class="keyword">with</span> tf.variable_scope(<span class="string">'unit_%d'</span> % (i + <span class="number">1</span>), values=[net]):</div><div class="line">                net = bottleneck(net, depth=base_depth * <span class="number">4</span>, </div><div class="line">                  depth_bottleneck=base_depth, stride=<span class="number">1</span>)</div><div class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">'unit_3'</span>, values=[net]):</div><div class="line">              net = bottleneck(net, depth=base_depth * <span class="number">4</span>, </div><div class="line">                depth_bottleneck=base_depth, stride=<span class="number">2</span>)</div><div class="line">            net = slim.utils.collect_named_outputs(end_points_collection, </div><div class="line">              sc.name, net)</div><div class="line"></div><div class="line">          <span class="keyword">with</span> tf.variable_scope(<span class="string">'block2'</span>, [net]) <span class="keyword">as</span> sc:</div><div class="line">            base_depth = <span class="number">128</span></div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">              <span class="keyword">with</span> tf.variable_scope(<span class="string">'unit_%d'</span> % (i + <span class="number">1</span>), values=[net]):</div><div class="line">                net = bottleneck(net, depth=base_depth * <span class="number">4</span>, </div><div class="line">                  depth_bottleneck=base_depth, stride=<span class="number">1</span>)</div><div class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">'unit_4'</span>, values=[net]):</div><div class="line">              net = bottleneck(net, depth=base_depth * <span class="number">4</span>, </div><div class="line">                depth_bottleneck=base_depth, stride=<span class="number">2</span>)</div><div class="line">            net = slim.utils.collect_named_outputs(end_points_collection, </div><div class="line">              sc.name, net)</div><div class="line"></div><div class="line">          <span class="keyword">with</span> tf.variable_scope(<span class="string">'block3'</span>, [net]) <span class="keyword">as</span> sc:</div><div class="line">            base_depth = <span class="number">256</span></div><div class="line"></div><div class="line">            num_units = <span class="number">6</span></div><div class="line">            <span class="keyword">if</span> depth == <span class="number">101</span>:</div><div class="line">              num_units = <span class="number">23</span></div><div class="line">            <span class="keyword">elif</span> depth == <span class="number">152</span>:</div><div class="line">              num_units = <span class="number">36</span></div><div class="line"></div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(num_units):</div><div class="line">              <span class="keyword">with</span> tf.variable_scope(<span class="string">'unit_%d'</span> % (i + <span class="number">1</span>), values=[net]):</div><div class="line">                net = bottleneck(net, depth=base_depth * <span class="number">4</span>, </div><div class="line">                  depth_bottleneck=base_depth, stride=<span class="number">1</span>)</div><div class="line">            net = slim.utils.collect_named_outputs(end_points_collection, </div><div class="line">              sc.name, net)</div><div class="line"></div><div class="line">          <span class="keyword">with</span> tf.variable_scope(<span class="string">'block4'</span>, [net]) <span class="keyword">as</span> sc:</div><div class="line">            base_depth = <span class="number">512</span></div><div class="line"></div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">              <span class="keyword">with</span> tf.variable_scope(<span class="string">'unit_%d'</span> % (i + <span class="number">1</span>), values=[net]):</div><div class="line">                net = bottleneck_hdc(net, depth=base_depth * <span class="number">4</span>, </div><div class="line">                  depth_bottleneck=base_depth, stride=<span class="number">1</span>, rate=<span class="number">2</span>, </div><div class="line">                  multi_grid=multi_grid)</div><div class="line">            net = slim.utils.collect_named_outputs(end_points_collection, </div><div class="line">              sc.name, net)</div></pre></td></tr></table></figure>
<p>这部分实现的变体的ResNet结构，包括带mutli-grid的残差模块由<a href="https://github.com/NanqingD/DeepLabV3-Tensorflow/blob/master/libs/nets/deeplabv3.py" target="_blank" rel="external">libs.nets.deeplabv3.py</a>中的<code>bottleneck_hdc</code>方法提供。</p>
<p>带mutli-grid策略的<code>bottleneck_hdc</code>残差结构代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@slim.add_arg_scope</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bottleneck_hdc</span><span class="params">(inputs,</span></span></div><div class="line"><span class="function"><span class="params">               depth,</span></span></div><div class="line"><span class="function"><span class="params">               depth_bottleneck,</span></span></div><div class="line"><span class="function"><span class="params">               stride,</span></span></div><div class="line"><span class="function"><span class="params">               rate=<span class="number">1</span>,</span></span></div><div class="line"><span class="function"><span class="params">               multi_grid=<span class="params">(<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>)</span>,</span></span></div><div class="line"><span class="function"><span class="params">               outputs_collections=None,</span></span></div><div class="line"><span class="function"><span class="params">               scope=None,</span></span></div><div class="line"><span class="function"><span class="params">               use_bounded_activations=False)</span>:</span></div><div class="line">  <span class="string">"""Hybrid Dilated Convolution Bottleneck.</span></div><div class="line"><span class="string">  Multi_Grid = (1,2,4)</span></div><div class="line"><span class="string">  See Understanding Convolution for Semantic Segmentation.</span></div><div class="line"><span class="string">  When putting together two consecutive ResNet blocks that use this unit, one</span></div><div class="line"><span class="string">  should use stride = 2 in the last unit of the first block.</span></div><div class="line"><span class="string">  Args:</span></div><div class="line"><span class="string">    inputs: A tensor of size [batch, height, width, channels].</span></div><div class="line"><span class="string">    depth: The depth of the ResNet unit output.</span></div><div class="line"><span class="string">    depth_bottleneck: The depth of the bottleneck layers.</span></div><div class="line"><span class="string">    stride: The ResNet unit's stride. Determines the amount of downsampling of</span></div><div class="line"><span class="string">      the units output compared to its input.</span></div><div class="line"><span class="string">    rate: An integer, rate for atrous convolution.</span></div><div class="line"><span class="string">    multi_grid: multi_grid sturcture.</span></div><div class="line"><span class="string">    outputs_collections: Collection to add the ResNet unit output.</span></div><div class="line"><span class="string">    scope: Optional variable_scope.</span></div><div class="line"><span class="string">    use_bounded_activations: Whether or not to use bounded activations. Bounded</span></div><div class="line"><span class="string">      activations better lend themselves to quantized inference.</span></div><div class="line"><span class="string">  Returns:</span></div><div class="line"><span class="string">    The ResNet unit's output.</span></div><div class="line"><span class="string">  """</span></div><div class="line">  <span class="keyword">with</span> tf.variable_scope(scope, <span class="string">'bottleneck_v1'</span>, [inputs]) <span class="keyword">as</span> sc:</div><div class="line">    depth_in = slim.utils.last_dimension(inputs.get_shape(), min_rank=<span class="number">4</span>)</div><div class="line">    <span class="comment"># 是否降采样</span></div><div class="line">    <span class="keyword">if</span> depth == depth_in:</div><div class="line">      shortcut = resnet_utils.subsample(inputs, stride, <span class="string">'shortcut'</span>)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">      shortcut = slim.conv2d(</div><div class="line">          inputs,</div><div class="line">          depth, [<span class="number">1</span>, <span class="number">1</span>],</div><div class="line">          stride=stride,</div><div class="line">          activation_fn=tf.nn.relu6 <span class="keyword">if</span> use_bounded_activations <span class="keyword">else</span> <span class="keyword">None</span>,</div><div class="line">          scope=<span class="string">'shortcut'</span>)</div><div class="line"></div><div class="line">    <span class="comment"># 残差结构的主分支</span></div><div class="line">    residual = slim.conv2d(inputs, depth_bottleneck, [<span class="number">1</span>, <span class="number">1</span>], stride=<span class="number">1</span>, </div><div class="line">      rate=rate*multi_grid[<span class="number">0</span>], scope=<span class="string">'conv1'</span>)</div><div class="line">    residual = resnet_utils.conv2d_same(residual, depth_bottleneck, <span class="number">3</span>, stride,</div><div class="line">      rate=rate*multi_grid[<span class="number">1</span>], scope=<span class="string">'conv2'</span>)</div><div class="line">    residual = slim.conv2d(residual, depth, [<span class="number">1</span>, <span class="number">1</span>], stride=<span class="number">1</span>, </div><div class="line">      rate=rate*multi_grid[<span class="number">2</span>], activation_fn=<span class="keyword">None</span>, scope=<span class="string">'conv3'</span>)</div><div class="line"></div><div class="line">    <span class="comment"># 是否后接激活函数</span></div><div class="line">    <span class="keyword">if</span> use_bounded_activations:</div><div class="line">      <span class="comment"># Use clip_by_value to simulate bandpass activation.</span></div><div class="line">      residual = tf.clip_by_value(residual, <span class="number">-6.0</span>, <span class="number">6.0</span>)</div><div class="line">      output = tf.nn.relu6(shortcut + residual)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">      output = tf.nn.relu(shortcut + residual)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> slim.utils.collect_named_outputs(outputs_collections,</div><div class="line">                                            sc.name,</div><div class="line">                                            output)</div></pre></td></tr></table></figure>
<h4 id="下面是关于aspp模块和后期的空洞卷积策略使用"><a href="#下面是关于aspp模块和后期的空洞卷积策略使用" class="headerlink" title="下面是关于aspp模块和后期的空洞卷积策略使用"></a>下面是关于aspp模块和后期的空洞卷积策略使用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div></pre></td><td class="code"><pre><div class="line">          <span class="keyword">if</span> aspp:</div><div class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">'aspp'</span>, [net]) <span class="keyword">as</span> sc:</div><div class="line">              aspp_list = []</div><div class="line">              branch_1 = slim.conv2d(net, <span class="number">256</span>, [<span class="number">1</span>,<span class="number">1</span>], stride=<span class="number">1</span>, </div><div class="line">                scope=<span class="string">'1x1conv'</span>)</div><div class="line">              branch_1 = slim.utils.collect_named_outputs(</div><div class="line">                end_points_collection, sc.name, branch_1)</div><div class="line">              aspp_list.append(branch_1)</div><div class="line"></div><div class="line">              <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">                branch_2 = slim.conv2d(net, <span class="number">256</span>, [<span class="number">3</span>,<span class="number">3</span>], stride=<span class="number">1</span>, rate=<span class="number">6</span>*(i+<span class="number">1</span>), scope=<span class="string">'rate&#123;&#125;'</span>.format(<span class="number">6</span>*(i+<span class="number">1</span>)))</div><div class="line">                branch_2 = slim.utils.collect_named_outputs(end_points_collection, sc.name, branch_2)</div><div class="line">                aspp_list.append(branch_2)</div><div class="line"></div><div class="line">              aspp = tf.add_n(aspp_list)</div><div class="line">              aspp = slim.utils.collect_named_outputs(end_points_collection, sc.name, aspp)</div><div class="line">            </div><div class="line">            <span class="comment"># 增加图像级特征，即全局平均池化</span></div><div class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">'img_pool'</span>, [net]) <span class="keyword">as</span> sc:</div><div class="line">              <span class="string">"""Image Pooling</span></div><div class="line"><span class="string">              See ParseNet: Looking Wider to See Better</span></div><div class="line"><span class="string">              """</span></div><div class="line">              pooled = tf.reduce_mean(net, [<span class="number">1</span>, <span class="number">2</span>], name=<span class="string">'avg_pool'</span>, </div><div class="line">                keep_dims=<span class="keyword">True</span>)</div><div class="line">              pooled = slim.utils.collect_named_outputs(end_points_collection, </div><div class="line">                sc.name, pooled)</div><div class="line"></div><div class="line">              pooled = slim.conv2d(pooled, <span class="number">256</span>, [<span class="number">1</span>,<span class="number">1</span>], stride=<span class="number">1</span>, scope=<span class="string">'1x1conv'</span>)</div><div class="line">              pooled = slim.utils.collect_named_outputs(end_points_collection, </div><div class="line">                sc.name, pooled)</div><div class="line"></div><div class="line">              pooled = tf.image.resize_bilinear(pooled, tf.shape(net)[<span class="number">1</span>:<span class="number">3</span>])</div><div class="line">              pooled = slim.utils.collect_named_outputs(end_points_collection, </div><div class="line">                sc.name, pooled)</div><div class="line">            </div><div class="line">            <span class="comment"># 将图像级特征融合到aspp中</span></div><div class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">'fusion'</span>, [aspp, pooled]) <span class="keyword">as</span> sc:</div><div class="line">              net = tf.concat([aspp, pooled], <span class="number">3</span>)</div><div class="line">              net = slim.utils.collect_named_outputs(end_points_collection, </div><div class="line">                sc.name, net)</div><div class="line"></div><div class="line">              net = slim.conv2d(net, <span class="number">256</span>, [<span class="number">1</span>,<span class="number">1</span>], stride=<span class="number">1</span>, scope=<span class="string">'1x1conv'</span>)</div><div class="line">              net = slim.utils.collect_named_outputs(end_points_collection, </div><div class="line">                sc.name, net)</div><div class="line">          </div><div class="line">          <span class="comment"># 如果不使用aspp， 则使用带mutli-grid的残差结构</span></div><div class="line">          <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">'block5'</span>, [net]) <span class="keyword">as</span> sc:</div><div class="line">              base_depth = <span class="number">512</span></div><div class="line"></div><div class="line">              <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">                <span class="keyword">with</span> tf.variable_scope(<span class="string">'unit_%d'</span> % (i + <span class="number">1</span>), values=[net]):</div><div class="line">                  net = bottleneck_hdc(net, depth=base_depth * <span class="number">4</span>, </div><div class="line">                    depth_bottleneck=base_depth, stride=<span class="number">1</span>, rate=<span class="number">4</span>)</div><div class="line">              net = slim.utils.collect_named_outputs(end_points_collection, </div><div class="line">                sc.name, net)</div><div class="line"></div><div class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">'block6'</span>, [net]) <span class="keyword">as</span> sc:</div><div class="line">              base_depth = <span class="number">512</span></div><div class="line"></div><div class="line">              <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">                <span class="keyword">with</span> tf.variable_scope(<span class="string">'unit_%d'</span> % (i + <span class="number">1</span>), values=[net]):</div><div class="line">                  net = bottleneck_hdc(net, depth=base_depth * <span class="number">4</span>, </div><div class="line">                    depth_bottleneck=base_depth, stride=<span class="number">1</span>, rate=<span class="number">8</span>)</div><div class="line">              net = slim.utils.collect_named_outputs(end_points_collection, </div><div class="line">                sc.name, net)</div><div class="line"></div><div class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">'block7'</span>, [net]) <span class="keyword">as</span> sc:</div><div class="line">              base_depth = <span class="number">512</span></div><div class="line"></div><div class="line">              <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">                <span class="keyword">with</span> tf.variable_scope(<span class="string">'unit_%d'</span> % (i + <span class="number">1</span>), values=[net]):</div><div class="line">                  net = bottleneck_hdc(net, depth=base_depth * <span class="number">4</span>, </div><div class="line">                    depth_bottleneck=base_depth, stride=<span class="number">1</span>, rate=<span class="number">16</span>)</div><div class="line">              net = slim.utils.collect_named_outputs(end_points_collection, </div><div class="line">                sc.name, net)</div><div class="line">          </div><div class="line">          <span class="comment"># 输出</span></div><div class="line">          <span class="keyword">with</span> tf.variable_scope(<span class="string">'logits'</span>,[net]) <span class="keyword">as</span> sc:</div><div class="line">            net = slim.conv2d(net, num_classes, [<span class="number">1</span>,<span class="number">1</span>], stride=<span class="number">1</span>, </div><div class="line">              activation_fn=<span class="keyword">None</span>, normalizer_fn=<span class="keyword">None</span>)</div><div class="line">            net = slim.utils.collect_named_outputs(end_points_collection, </div><div class="line">            sc.name, net)</div><div class="line"></div><div class="line">          end_points = slim.utils.convert_collection_to_dict(</div><div class="line">              end_points_collection)</div><div class="line"></div><div class="line">          <span class="keyword">return</span> net, end_points</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">  x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">3</span>])</div><div class="line"></div><div class="line">  net, end_points = deeplabv3(x, <span class="number">21</span>)</div><div class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> end_points:</div><div class="line">    print(i, end_points[i])</div></pre></td></tr></table></figure>
<p>代码本身还是很容易理解的~</p>
<hr>
<p>到这里整个DeepLabv3就算结束了~</p>
<hr>
<hr>
<hr>
<h1 id="DeepLab系列总结"><a href="#DeepLab系列总结" class="headerlink" title="DeepLab系列总结"></a>DeepLab系列总结</h1><p>截图内容源于<a href="http://web.eng.tau.ac.il/deep_learn/wp-content/uploads/2017/12/Rethinking-Atrous-Convolution-for-Semantic-Image-Segmentation-1.pdf" target="_blank" rel="external">官方的PPT</a>。</p>
<p>关于DeepLabv1,DeepLabv2,DeepLabv3汇总：</p>
<ul>
<li><p><strong>DeepLabv1</strong>：  </p>
<ul>
<li>原文地址：<a href="https://arxiv.org/pdf/1412.7062v3.pdf" target="_blank" rel="external">DeepLabv1: Semantic image segmentation with deep convolutional nets and fully connected CRFs</a></li>
<li>收录：ICLR 2015 (International Conference on Learning Representations)</li>
<li>代码:<ul>
<li><a href="https://bitbucket.org/deeplab/deeplab-public/overview" target="_blank" rel="external">bitbucket-Caffe</a></li>
<li><a href="https://github.com/TheLegendAli/DeepLab-Context" target="_blank" rel="external">github-Caffe</a></li>
</ul>
</li>
<li>blog：<a href="http://blog.csdn.net/u011974639/article/details/79134409" target="_blank" rel="external">CSDN</a></li>
</ul>
</li>
<li><p><strong>DeepLabv2</strong>：</p>
<ul>
<li>原文地址：<a href="https://arxiv.org/abs/1606.00915" target="_blank" rel="external">DeepLabv2:DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</a></li>
<li>收录：TPAMI2017 (IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017)</li>
<li>代码:<ul>
<li><a href="https://github.com/DrSleep/tensorflow-deeplab-resnet" target="_blank" rel="external">TensorFlow</a></li>
<li><a href="https://bitbucket.org/aquariusjay/deeplab-public-ver2" target="_blank" rel="external">bitbucket-Caffe</a></li>
</ul>
</li>
<li>blog:<a href="http://blog.csdn.net/u011974639/article/details/79138653" target="_blank" rel="external">CSDN</a></li>
</ul>
</li>
<li><p><strong>DeepLabv3</strong></p>
<ul>
<li>原文地址：<a href="https://arxiv.org/abs/1706.05587" target="_blank" rel="external">DeepLabv3:Rethinking Atrous Convolution for Semantic Image Segmentation</a>   </li>
<li>代码:<ul>
<li><a href="https://github.com/NanqingD/DeepLabV3-Tensorflow" target="_blank" rel="external">TensorFlow</a></li>
</ul>
</li>
<li>blog：<a href="http://blog.csdn.net/u011974639/article/details/79144773" target="_blank" rel="external">CSDN</a></li>
</ul>
</li>
</ul>
<h2 id="DeepLab系列针对的Task"><a href="#DeepLab系列针对的Task" class="headerlink" title="DeepLab系列针对的Task"></a>DeepLab系列针对的Task</h2><p>DeepLab是针对语义分割(Semantic Segmentation)任务提出的深度学习系统：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/g1mJ1d2GBc.png" alt="mark"></p>
<p>语义分割的要求：</p>
<ul>
<li>语义分割是对图像做密集的分割任务，分割每个像素到指定类别上</li>
<li>将图像分割成几个有意义的目标</li>
<li>给对象分配指定类型标签</li>
</ul>
<p>语义分割的用途：</p>
<ul>
<li>自动驾驶</li>
<li>医疗辅助</li>
</ul>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/9iAG3JkF4B.png" alt="mark"></p>
<hr>
<h2 id="DeepLabv1-amp-DeepLabv2"><a href="#DeepLabv1-amp-DeepLabv2" class="headerlink" title="DeepLabv1 &amp; DeepLabv2"></a>DeepLabv1 &amp; DeepLabv2</h2><ul>
<li>使用DCNN做密集的分类任务，产生的预测图有目标大概的位置，但比较粗糙</li>
<li>使用条件随机场(CRF)细化分割结果</li>
</ul>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/984fKB8f8G.png" alt="mark"></p>
<h3 id="核心解决思路"><a href="#核心解决思路" class="headerlink" title="核心解决思路"></a>核心解决思路</h3><table>
<thead>
<tr>
<th>对于标准的DCNN有哪些问题？</th>
<th>针对这些问题，DeepLab的解决办法</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.<strong>分辨率</strong>： 输出特征分辨率较小<br> 2.<strong>池化</strong>： 对于输入变换具有内在不变性</td>
<td>1.使用空洞卷积<br>2. 使用CRF</td>
</tr>
</tbody>
</table>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/c2KLkkL4lE.png" alt="mark"></p>
<h4 id="DCNN中使用空洞卷积"><a href="#DCNN中使用空洞卷积" class="headerlink" title="DCNN中使用空洞卷积"></a>DCNN中使用空洞卷积</h4><p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/bJ9l0ABbj3.png" alt="mark"></p>
<ul>
<li>移除原网络最后两个池化层</li>
<li>使用$rate=2$的空洞卷积采样</li>
</ul>
<p>如上图右下所示，标准的卷积只能获取原图1/4的内容，而新的带孔卷积可以在全图上获取信息。</p>
<p>DeepLabv1到DeepLabv2有一个变化：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/kG35IL1J3F.png" alt="mark"></p>
<p>由左边到右边，主要是在DCNN中应用了空洞卷积密集的提取特征，左边的输出步幅是16，需要上采样16倍得到预测结果，可以看到结果是比较模糊的；而右边是在DCNN中使用空洞卷积，保持步幅为8，只需要上采样8倍，结果清晰了很多。</p>
<h4 id="CRF部分"><a href="#CRF部分" class="headerlink" title="CRF部分"></a>CRF部分</h4><p>DCNN存在分类和定位之间的折中问题，预测到目标的大概位置但比较模糊。</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/68GkJDiC2F.png" alt="mark"></p>
<p>CRF尝试找到图像像素之间的关系： 相近且相似的像素大概率为同一标签；CRF考虑像素的概率分配标签；迭代细化结果。</p>
<h3 id="模型结构介绍"><a href="#模型结构介绍" class="headerlink" title="模型结构介绍"></a>模型结构介绍</h3><h4 id="DeepLabv1结构介绍"><a href="#DeepLabv1结构介绍" class="headerlink" title="DeepLabv1结构介绍"></a>DeepLabv1结构介绍</h4><p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/7879h4g497.png" alt="mark"><br>DeepLabv1是在VGG16的基础上做了修改：</p>
<ul>
<li>VGG16的全连接层转为卷积</li>
<li>最后的两个池化层去掉了下采样</li>
<li>后续卷积层的卷积核改为了空洞卷积</li>
<li>在ImageNet上预训练的VGG16权重上做finetune</li>
</ul>
<p>可视化结果如下：<br><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/hkHGlL4gL3.png" alt="mark"></p>
<h4 id="DeepLabv2结构介绍"><a href="#DeepLabv2结构介绍" class="headerlink" title="DeepLabv2结构介绍"></a>DeepLabv2结构介绍</h4><p>DeepLabv2在DeepLabv1上做了改进：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/AClklDIKdD.png" alt="mark"></p>
<ul>
<li>用多尺度获得更好的分割效果(使用ASPP)</li>
<li>基础层由VGG16转为ResNet</li>
<li>使用不同的学习策略(poly)</li>
</ul>
<h5 id="ASPP模块-1"><a href="#ASPP模块-1" class="headerlink" title="ASPP模块"></a>ASPP模块</h5><table>
<thead>
<tr>
<th>为什么要提出ASPP？</th>
<th>解决思路</th>
<th>实施办法</th>
</tr>
</thead>
<tbody>
<tr>
<td>语义分割挑战：在多尺度上存储目标</td>
<td>在给定的特征层上使用不同采样率的卷积有效的重采样</td>
<td>使用不同采样率的空洞卷积并行采样</td>
</tr>
</tbody>
</table>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/EliFfHIjdC.png" alt="mark"></p>
<p>ASPP中在给定的<code>Input Feature Map</code>上以$r=(6,12,18,24)$的$3×3$空洞卷积并行采样。</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/KLB8ebIIm3.png" alt="mark"></p>
<p>ASPP各个空洞卷积分支采样后结果最后融合到一起(通道相同，做像素加)，得到最终预测结果.</p>
<p>DeepLabv2可视化结果：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/96E8cmakDl.png" alt="mark"></p>
<h3 id="DeepLabv1-amp-DeepLabv2优势"><a href="#DeepLabv1-amp-DeepLabv2优势" class="headerlink" title="DeepLabv1 &amp; DeepLabv2优势"></a>DeepLabv1 &amp; DeepLabv2优势</h3><p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/GEdkAbblb8.png" alt="mark"></p>
<ul>
<li>速度上： 使用空洞卷积的Dense DCNN达到8fps，全连接的CRF需要0.5s</li>
<li>精准度：在几个先进的数据集上达到了先进的结果</li>
<li>建议性：系统由两个成熟的模块组成，DCNNs和CRFs</li>
</ul>
<hr>
<h2 id="DeepLabv3-1"><a href="#DeepLabv3-1" class="headerlink" title="DeepLabv3"></a>DeepLabv3</h2><h3 id="相比DeepLabv1-amp-DeepLabv2的改变"><a href="#相比DeepLabv1-amp-DeepLabv2的改变" class="headerlink" title="相比DeepLabv1 &amp; DeepLabv2的改变"></a>相比DeepLabv1 &amp; DeepLabv2的改变</h3><p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/Ej5HmI5iAI.png" alt="mark"></p>
<ul>
<li>提出了更通用的框架，适用于任何网络</li>
<li>复制了ResNet最后的block，并级联起来</li>
<li>在ASPP中使用BN层</li>
<li><strong>没有</strong>使用CRF</li>
</ul>
<h3 id="模型结构介绍-1"><a href="#模型结构介绍-1" class="headerlink" title="模型结构介绍"></a>模型结构介绍</h3><p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/KJbbHfe0D2.png" alt="mark"></p>
<ul>
<li>复制ResNet最后一个block多个副本，级联到一起<ul>
<li>在本文中,block5-7是block4的副本</li>
</ul>
</li>
<li>每个block中包含三个卷积(使用Mutli-gird策略)</li>
<li>最后一个block的最后一个卷积步长为2(???)</li>
<li>为了维持原图尺寸，使用不同的采样率(每层采样率乘2)空洞卷积代替原卷积</li>
</ul>
<h4 id="ASPP模块-2"><a href="#ASPP模块-2" class="headerlink" title="ASPP模块"></a>ASPP模块</h4><p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/0dCc9lH84l.png" alt="mark"></p>
<p>相比于DeepLabv2的ASPP模块，有以下变化和问题：</p>
<ul>
<li>ASPP中应用了BN层</li>
<li>随着采样率的增加，滤波器中有效的权重减少了(有效权重减少，难以捕获原距离信息，这要求合理控制采样率的设置)</li>
<li>使用模型最后的特征映射的全局平均池化(为了克服远距离下有效权重减少的问题)</li>
</ul>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/HDl01aKf1h.png" alt="mark"></p>
<p>新的ASPP模块包括：</p>
<ul>
<li>一个$1×1$卷积和3个$3×3$的空洞卷积(采样率为(6,12,18))，每个卷积核都有256个且都有BN层</li>
<li>包含图像级特征(即全局平均池化)    </li>
</ul>
<p>所有分支得到的结果通过$1×1$卷积级联到一起得到最终结果。</p>
<h3 id="DeepLabv3的实验结果"><a href="#DeepLabv3的实验结果" class="headerlink" title="DeepLabv3的实验结果"></a>DeepLabv3的实验结果</h3><p>在PASCAL VOC 2012测试集上，相比于DeepLabv2的77.69%，DeepLabv3有2%的提升：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/e1KCgi7l4b.png" alt="mark"></p>
<p>最好的结果包含：</p>
<ul>
<li>ASPP</li>
<li>输出步幅为8</li>
<li>翻转和随机缩放的数据增强</li>
</ul>
<p>可视化结果：</p>
<p><img src="http://owv7la1di.bkt.clouddn.com/blog/180124/ebKKci98E8.png" alt="mark"></p>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>Thanks for your support!</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatqc.jpg" alt="DFan WeChat Pay"/>
        <p>WeChat Pay</p>
      </div>
    

    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-Convolutional-NetWork/" rel="tag"># Deep Convolutional NetWork</a>
          
            <a href="/tags/Semantic-Segmentation/" rel="tag"># Semantic Segmentation</a>
          
            <a href="/tags/DeepLab/" rel="tag"># DeepLab</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/01/08/语义分割论文-ICNet/" rel="next" title="语义分割论文-ICNet">
                <i class="fa fa-chevron-left"></i> 语义分割论文-ICNet
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/01/26/轻量级网络-MobileNetv1/" rel="prev" title="轻量级网络-MobileNetV1">
                轻量级网络-MobileNetV1 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
  <a class="jiathis_button_tsina"></a>
  <a class="jiathis_button_tqq"></a>
  <a class="jiathis_button_weixin"></a>
  <a class="jiathis_button_cqq"></a>
  <a class="jiathis_button_douban"></a>
  <a class="jiathis_button_renren"></a>
  <a class="jiathis_button_qzone"></a>
  <a class="jiathis_button_kaixin001"></a>
  <a class="jiathis_button_copy"></a>
  <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank"></a>
  <a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
  var jiathis_config={
    hideMore:false
  }
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END -->

      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zMTA1OC83NjA2"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="DFan" />
          <p class="site-author-name" itemprop="name">DFan</p>
           
              <p class="site-description motion-element" itemprop="description">合肥工业大学在读</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">30</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">32</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/hfut-fan" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://blog.csdn.net/u011974639" target="_blank" title="CSDN">
                  
                    <i class="fa fa-fw fa-id-card"></i>
                  
                    
                      CSDN
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#DeepLabv1"><span class="nav-text">DeepLabv1</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract"><span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction"><span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Related-Work"><span class="nav-text">Related Work</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#密集分类下的卷积神经网络"><span class="nav-text">密集分类下的卷积神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#空洞卷积的使用"><span class="nav-text">空洞卷积的使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CRF在语义分割上的应用"><span class="nav-text">CRF在语义分割上的应用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多尺度预测"><span class="nav-text">多尺度预测</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Experiment"><span class="nav-text">Experiment</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CRF和多尺度的表现"><span class="nav-text">CRF和多尺度的表现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#离散卷积的表现"><span class="nav-text">离散卷积的表现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#与其他模型相比"><span class="nav-text">与其他模型相比</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conclusion"><span class="nav-text">Conclusion</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DeepLabv2"><span class="nav-text">DeepLabv2</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-1"><span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-1"><span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Related-Work-1"><span class="nav-text">Related Work</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Method"><span class="nav-text">Method</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#空洞卷积用于密集特征提取和扩大感受野"><span class="nav-text">空洞卷积用于密集特征提取和扩大感受野</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用ASPP模块表示多尺度图像"><span class="nav-text">使用ASPP模块表示多尺度图像</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用全连接CRF做结构预测用于恢复边界精度"><span class="nav-text">使用全连接CRF做结构预测用于恢复边界精度</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Experiment-1"><span class="nav-text">Experiment</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#PASCAL-VOC-2012"><span class="nav-text">PASCAL VOC 2012</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#学习策略实验"><span class="nav-text">学习策略实验</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ASPP模块实验"><span class="nav-text">ASPP模块实验</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#不同深度网络和多尺度处理实验"><span class="nav-text">不同深度网络和多尺度处理实验</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PASCAL-Context"><span class="nav-text">PASCAL-Context</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PASCAL-Person-Part"><span class="nav-text">PASCAL-Person-Part</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cityscapes"><span class="nav-text">Cityscapes</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#失败案例"><span class="nav-text">失败案例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conclusion-1"><span class="nav-text">Conclusion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#代码分析"><span class="nav-text">代码分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#DeepLab-ResNet结构"><span class="nav-text">DeepLab_ResNet结构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ResNet的前体"><span class="nav-text">ResNet的前体</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ResNet的变体部分"><span class="nav-text">ResNet的变体部分</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ASPP模块"><span class="nav-text">ASPP模块</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DeepLabv3"><span class="nav-text">DeepLabv3</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-2"><span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-2"><span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Related-Work-2"><span class="nav-text">Related Work</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Method-1"><span class="nav-text">Method</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#空洞卷积应用于密集的特征提取"><span class="nav-text">空洞卷积应用于密集的特征提取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#深层次的空洞卷积"><span class="nav-text">深层次的空洞卷积</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Experiment-2"><span class="nav-text">Experiment</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Going-Deeper-with-Atrous-Convolution实验"><span class="nav-text">Going Deeper with Atrous Convolution实验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Atrous-Spatial-Pyramid-Pooling实验"><span class="nav-text">Atrous Spatial Pyramid Pooling实验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#在PASCAL-VOC-2012上表现："><span class="nav-text">在PASCAL VOC 2012上表现：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cityscapes表现"><span class="nav-text">Cityscapes表现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#其他参数的影响"><span class="nav-text">其他参数的影响</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conclusion-2"><span class="nav-text">Conclusion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#代码分析-1"><span class="nav-text">代码分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#训练脚本分析"><span class="nav-text">训练脚本分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#创建训练模型-amp-计算loss"><span class="nav-text">创建训练模型 & 计算loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#训练参数设置"><span class="nav-text">训练参数设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建交叉验证模型，并设置输出值"><span class="nav-text">创建交叉验证模型，并设置输出值</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#训练模型"><span class="nav-text">训练模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型分析"><span class="nav-text">模型分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#deeplabv3中ResNet变体"><span class="nav-text">deeplabv3中ResNet变体</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#下面是关于aspp模块和后期的空洞卷积策略使用"><span class="nav-text">下面是关于aspp模块和后期的空洞卷积策略使用</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DeepLab系列总结"><span class="nav-text">DeepLab系列总结</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#DeepLab系列针对的Task"><span class="nav-text">DeepLab系列针对的Task</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DeepLabv1-amp-DeepLabv2"><span class="nav-text">DeepLabv1 & DeepLabv2</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#核心解决思路"><span class="nav-text">核心解决思路</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#DCNN中使用空洞卷积"><span class="nav-text">DCNN中使用空洞卷积</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CRF部分"><span class="nav-text">CRF部分</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型结构介绍"><span class="nav-text">模型结构介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#DeepLabv1结构介绍"><span class="nav-text">DeepLabv1结构介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DeepLabv2结构介绍"><span class="nav-text">DeepLabv2结构介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#ASPP模块-1"><span class="nav-text">ASPP模块</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DeepLabv1-amp-DeepLabv2优势"><span class="nav-text">DeepLabv1 & DeepLabv2优势</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DeepLabv3-1"><span class="nav-text">DeepLabv3</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#相比DeepLabv1-amp-DeepLabv2的改变"><span class="nav-text">相比DeepLabv1 & DeepLabv2的改变</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型结构介绍-1"><span class="nav-text">模型结构介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ASPP模块-2"><span class="nav-text">ASPP模块</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DeepLabv3的实验结果"><span class="nav-text">DeepLabv3的实验结果</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2017 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">DFan</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  






  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
